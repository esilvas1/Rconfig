---
title: "Análisis Exploratorio de Datos y Aplicación de Regresion Lineal Simple"
author: "Edwin Silva Salas - Actividad 3 - Metodos y Simulación Estadisticas"
date: "`r Sys.Date()`"
output:
  html_document:
    toc: true
    toc_depth: 4
    code_folding: hide
    number_sections: true
---

```{r install-packages, include=FALSE}
required_packages <- c("tidyverse", "knitr", "kableExtra", "broom", "ggplot2", 
                       "forcats", "scales", "dplyr", "gridExtra", "lmtest", "forecast")

missing_packages <- required_packages[!required_packages %in% installed.packages()[,"Package"]]

if(length(missing_packages) > 0) {
  install.packages(missing_packages, dependencies = TRUE)
}

# Load all packages
lapply(required_packages, library, character.only = TRUE)
```


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, message = FALSE, warning = FALSE, fig.width = 8, fig.height = 5)
library(tidyverse)
library(knitr)
library(kableExtra)

# helper to safely read CSVs produced by EDA
safe_read <- function(path) {
  if (file.exists(path)) readr::read_csv(path) else tibble()
}

image_exists <- function(path) {
  file.exists(path)
}

# Cargar los datos originales para graficar en vivo
df_mat <- if (file.exists("student-mat.csv")) readr::read_csv2("student-mat.csv") else tibble()
df_por <- if (file.exists("student-por.csv")) readr::read_csv2("student-por.csv") else tibble()
```

# Resumen ejecutivo

Este informe contiene un análisis exploratorio de datos (EDA) para los conjuntos `student_mat.csv` y `student_por.csv`.Descargados de la url **https://archive.ics.uci.edu/dataset/320/student+performance**, Este informe incluye tablas descriptivas, identificación de valores faltantes, detección de outliers por la regla IQR, matrices y mapas de correlación, y gráficos de dispersión de la calificación o nota final de cada estudiante (G3) frente a las variables con mayor correlación.


# Aplicación: Análisis Exploratorio de Datos (EDA)
Se descarga de la ubicacion URL mencionda anteriormente un archivo (*.zip) con el contenido de los datos en archivos (*.csv) como insumo de esta actividad, se realiza su respectivo analisis EDA y posterior aplicacion del Modelo de Regresion Lineal Simple, **Simple Lineal Regression Model (SLRM)**

```{r files-check}
# confirmamos que los archivos base existen en el proyecto
cat("student-mat.csv:", file.exists("student-mat.csv"), "\n")
cat("student-por.csv:", file.exists("student-por.csv"), "\n")
```

Se muestran los nombres de las columnas o variables de los datasets **student_xxx** y se describe en español su significado o descripcion de columna en la **Tabla A9**:

```{r codebook_table, echo=FALSE, message=FALSE, warning=FALSE}
library(dplyr); library(tidyr); library(knitr); library(kableExtra)

# Reconstruir codebook_tbl si no existe (fallback rápido)
if (!exists("codebook_tbl")) {
  spanish_dict <- c(
    school="Escuela (GP/MS)", sex="Sexo (F/M)", age="Edad (años)", address="Dirección (U/R)",
    famsize="Tamaño familia (LE3/GT3)", Pstatus="Estado padres (T/A)", Medu="Educación madre (0-4)",
    Fedu="Educación padre (0-4)", Mjob="Trabajo madre", Fjob="Trabajo padre", reason="Razón",
    guardian="Tutor", traveltime="Tiempo viaje (1-4)", studytime="Tiempo estudio (1-4)",
    failures="Reprobadas previas", schoolsup="Apoyo escolar", famsup="Apoyo familiar",
    paid="Clases pagadas", activities="Actividades extra", nursery="Guardería", higher="Deseo superior",
    internet="Internet en casa", romantic="Relación romántica", famrel="Relación familiar (1-5)",
    freetime="Tiempo libre (1-5)", goout="Salir con amigos (1-5)", Dalc="Alcohol entre semana (1-5)",
    Walc="Alcohol fin de semana (1-5)", health="Salud (1-5)", absences="Ausencias", G1="Nota periodo 1",
    G2="Nota periodo 2", G3="Nota final (objetivo)"
  )
  all_cols <- unique(c(names(df_mat), names(df_por)))
  codebook_tbl <- tibble(variable = all_cols) %>%
    mutate(descripcion = spanish_dict[variable]) %>%
    mutate(descripcion = ifelse(is.na(descripcion), NA_character_, descripcion))
}

# Mostrar en 4 columnas (variable/descripcion como pares)
n <- nrow(codebook_tbl)
if (n > 0) {
  rows_per_col <- ceiling(n / 4)
  # dividir en 4 bloques por orden
  idx <- rep(1:4, each = rows_per_col)[1:n]
  blocks <- split(codebook_tbl, idx)
  pad_block <- function(df) {
    if (nrow(df) < rows_per_col) {
      bind_rows(df, tibble(variable = rep(NA_character_, rows_per_col - nrow(df)),
                           descripcion = rep(NA_character_, rows_per_col - nrow(df))))
    } else df
  }
  blocks <- lapply(blocks, pad_block)
  wide <- bind_cols(
    blocks[[1]] %>% rename(variable1 = variable, desc1 = descripcion),
    blocks[[2]] %>% rename(variable2 = variable, desc2 = descripcion),
    blocks[[3]] %>% rename(variable3 = variable, desc3 = descripcion),
    blocks[[4]] %>% rename(variable4 = variable, desc4 = descripcion)
  ) %>% mutate_all(~replace_na(as.character(.), ""))
  knitr::kable(wide, caption = "Tabla A9: Diccionario de columnas (4 columnas)", booktabs = TRUE) %>%
    kable_styling(full_width = FALSE)
} else {
  cat("No hay columnas para mostrar.\n")
}
```


## Resumen numérico: missing, Outlier and Correlation (student_mat)
A continuació se genera un resumen numerico del dataset **student_mat** reflejando estadisticamente valores que visualizan si es necesario imputar datos o limpiar registros en cuento a valores atipico o faltantes:

```{r mat-numeric}
# Crear resumen numérico directamente a partir de student-mat.csv
if (nrow(df_mat) > 0) {
  num_sum_mat <- df_mat %>%
    select(where(is.numeric)) %>%
    summarise(across(everything(), list(
      mean = ~mean(.x, na.rm = TRUE),
      sd = ~sd(.x, na.rm = TRUE),
      median = ~median(.x, na.rm = TRUE),
      min = ~min(.x, na.rm = TRUE),
      max = ~max(.x, na.rm = TRUE),
      missing = ~sum(is.na(.x))
    ), .names = "{.col}_{.fn}"))

  # Convertir a formato largo para mostrar
  num_sum_mat_long <- num_sum_mat %>%
    pivot_longer(everything(), names_to = "metric", values_to = "value") %>%
    separate(metric, into = c("variable","stat"), sep = "_(?=[^_]+$)") %>%
    pivot_wider(names_from = stat, values_from = value) %>%
    arrange(variable)

  num_sum_mat_long %>%
    kable(digits = 3, caption = "Tabla A5: Resumen numerico student_mat") %>%
    kable_styling(full_width = FALSE)
} else cat("Archivo student-mat.csv no encontrado o vacío.\n")
```

En el siguiente espacio se desea revisar toda la data **student_mat** con el fin de determinar si existen valores faltantes y asi iniciar un procedimiento de imputación de datos:

```{r mat-missing}
# Tabla de valores faltantes por variable (student_mat) — mostrar solo variables con missing > 0
if (nrow(df_mat) > 0) {
  missing_mat <- df_mat %>%
    summarise(across(everything(), ~sum(is.na(.)))) %>%
    pivot_longer(everything(), names_to = "variable", values_to = "missing") %>%
    arrange(desc(missing))

  missing_mat_filtered <- missing_mat %>% filter(missing > 0)

  if (nrow(missing_mat_filtered) > 0) {
    missing_mat_filtered %>%
      kable(digits = 0, caption = "Missing values — student_mat (solo variables con missing)") %>%
      kable_styling(full_width = FALSE)
  } else {
    cat("No se detectaron valores faltantes en student_mat.\n")
  }
} else cat("Archivo student-mat.csv no encontrado o vacío.\n")
```
Y como se puede visualizar el codigo arroja que la data no contiene valores faltantes, por lo que continuaremos con la sigueinte sesion.

### Boxplots y Correlación

A continuacion se grafican las variables numericas graficos **Boxplots** para visualizar las diferentes variables que presentan alguna posible variacion atipica en su conjunto de valores, como se pueden ver en las variables: traveltime, studytime, G2, freetime, Fedu, famrel, failures, Dalc, age, y absences en la grafica A1:


```{r mat_plots}
if (nrow(df_mat)>0) {
  library(ggplot2)
  # Boxplots por variables numéricas
  nums <- df_mat %>% select(where(is.numeric))
  if (ncol(nums) > 0) {
    nums_long <- nums %>% pivot_longer(everything(), names_to = "variable", values_to = "value")
    p2 <- ggplot(nums_long, aes(x = variable, y = value)) +
      geom_boxplot(outlier.size = 1, fill = "#74a9cf") +
      coord_flip() +
      labs(title = "Grafica A1: Boxplots variables numéricas (student_mat)") +
      theme_minimal()
    print(p2)
  }
} else {
  cat("Archivo student-mat.csv no encontrado o vacío.\n")
}
```

Aplicando la funcionalidad de detección de **Outliers** visualizamos en la sigueinte tabla (Tabla A4) la cantidad de valores que no se ajustan al rango o regla **IQR**.

```{r mat-outliers}
# Detección de outliers por regla IQR para variables numéricas
if (nrow(df_mat) > 0) {
  nums <- df_mat %>% select(where(is.numeric))
  out_mat <- map_dfr(names(nums), function(var) {
    x <- nums[[var]]
    if (all(is.na(x))) return(tibble(variable = var, outlier_count = 0))
    q1 <- quantile(x, 0.25, na.rm = TRUE)
    q3 <- quantile(x, 0.75, na.rm = TRUE)
    iqr <- q3 - q1
    lower <- q1 - 1.5 * iqr
    upper <- q3 + 1.5 * iqr
    tibble(variable = var, outlier_count = sum(x < lower | x > upper, na.rm = TRUE))
  })

  out_mat %>% filter(outlier_count > 0) %>%
    kable(digits = 0, caption = "Tabla A4: Outliers detectados (IQR) — student_mat") %>%
    kable_styling(full_width = FALSE)
} else cat("Archivo student-mat.csv no encontrado o vacío.\n")
```

En el siguiente grafico (Grafica A2) se realiza un grafico de correlación con las variables numericas con el fin de encontrar la posible relacion que puede existir en algunas variables tales como G1, G2, G3, Walc, Dalc, Fedu y Medu.

```{r mat_correlacion}
if (nrow(df_mat)>0) {
  library(ggplot2)
  # Mapa de correlación (numéricas)
  nums <- df_mat %>% select(where(is.numeric))
  if (ncol(nums) >= 2) {
    cor_mat <- cor(nums, use = "pairwise.complete.obs")
    cor_df <- as.data.frame(as.table(cor_mat))
    p3 <- ggplot(cor_df, aes(Var1, Var2, fill = Freq)) +
      geom_tile() +
      scale_fill_gradient2(low = "blue", mid = "white", high = "red", midpoint = 0) +
      theme_minimal() +
      theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
      labs(title = "Grafica A2: Mapa de correlación (num) - student_mat") +
      coord_fixed()
    print(p3)
  }
} else {
  cat("Archivo student-mat.csv no encontrado o vacío.\n")
}
```


Teniendo en cuenta aquellas que superan el parametro de correlaciones fuertes (|r|>=0.7) se tiene el siguiente listado:

```{r mat-strong}
# Correlaciones fuertes |r| >= 0.7 (numéricas)
if (nrow(df_mat) > 0) {
  nums <- df_mat %>% select(where(is.numeric))
  strong_mat <- tibble()
  if (ncol(nums) >= 2) {
    cor_mat <- cor(nums, use = "pairwise.complete.obs")
    cor_df <- as.data.frame(as.table(cor_mat))
    strong_mat <- cor_df %>%
      filter(Var1 != Var2) %>%
      mutate(abs_r = abs(Freq)) %>%
      filter(abs_r >= 0.7) %>%
      arrange(desc(abs_r)) %>%
      rename(variable1 = Var1, variable2 = Var2, r = Freq) %>%
      select(variable1, variable2, r)
  }

  if (nrow(strong_mat) > 0) {
    strong_mat %>% kable(digits = 3, caption = "Tabla A3: Correlaciones fuertes (|r|>=0.7) — student_mat") %>% kable_styling(full_width = FALSE)
  } else cat("No se detectaron correlaciones fuertes (|r|>=0.7) en variables numéricas.\n")
} else cat("Archivo student-mat.csv no encontrado o vacío.\n")
```

Para visualizar gráficamente las relaciones con mayor correlación (|r| notable), se muestran a continuación diagramas de dispersión entre G3 y cada variable relevante, junto con su línea de tendencia.

```{r mat-scatter}
if (nrow(df_mat)>0) {
  nums <- df_mat %>% select(where(is.numeric))
  if ("G3" %in% names(nums) && ncol(nums) >= 2) {
    cor_with_G3 <- cor(nums, use = "pairwise.complete.obs")[, "G3", drop = FALSE]
    cor_with_G3 <- tibble(variable = rownames(cor_with_G3), corr = cor_with_G3[,1]) %>%
      filter(variable != "G3") %>%
      arrange(desc(abs(corr)))
    top_vars <- head(cor_with_G3$variable, 6)
    if (length(top_vars) > 0) {
      scatter_df <- df_mat %>% select(all_of(c("G3", top_vars))) %>% pivot_longer(-G3, names_to = "variable", values_to = "value")
      p4 <- ggplot(scatter_df, aes(x = value, y = G3)) +
        geom_point(alpha = 0.6, size = 1.5, color = "#2b8cbe") +
        geom_smooth(method = "lm", se = FALSE, color = "red") +
        facet_wrap(~variable, scales = "free_x") +
        labs(title = "Grafico A6: G3 vs variables con mayor correlación (student_mat)") +
        theme_minimal()
      print(p4)
    }
  }
} else cat("Archivo student-mat.csv no encontrado o vacío.\n")
```

De los variables evaluadas, únicamente G1 y G2 alcanzan una correlación aceptable con la nota final (G3), por lo que se recomiendan como predictores prioritarios en la regresión lineal simple.


**Análisis Categorico**

Con el objetivo de analizar el comportamiento de las variables categóricas y detectar posibles valores atípicos, se presenta a continuación un gráfico que muestra la distribución de cada categoría.

```{r mat-cat-bars-improved, fig.width=12, fig.height=10, echo=FALSE}
library(ggplot2)
library(forcats)
library(scales)
library(dplyr)

cat_vars <- df_mat %>% select(where(~ is.character(.) || is.factor(.)))

if (nrow(df_mat) > 0 && ncol(cat_vars) > 0) {

  # Long format y conteo inicial
  long_cat <- cat_vars %>%
    mutate(across(everything(), ~ as.character(.))) %>%
    pivot_longer(everything(), names_to = "variable", values_to = "value") %>%
    filter(!is.na(value))

  counts <- long_cat %>%
    group_by(variable, value) %>%
    summarise(n = n(), .groups = "drop") %>%
    group_by(variable) %>%
    arrange(variable, desc(n)) %>%
    mutate(rank = row_number()) %>%
    ungroup()

  # Agrupar categorías raras por variable (top 10 -> mostrar; resto -> "Other")
  counts2 <- counts %>%
    mutate(value2 = if_else(rank <= 10, value, "Other")) %>%
    group_by(variable, value2) %>%
    summarise(n = sum(n), .groups = "drop") %>%
    group_by(variable) %>%
    mutate(pct = n / sum(n) * 100) %>%
    ungroup()

  # Preparar factor reordenado dentro de cada facet
  counts2 <- counts2 %>%
    group_by(variable) %>%
    mutate(value2 = fct_reorder2(value2, n, n)) %>%
    ungroup()

  # Plot: barras horizontales por variable (faceteado)
  p <- ggplot(counts2, aes(x = value2, y = n, fill = pct)) +
    geom_col(width = 0.7, show.legend = TRUE) +
    geom_text(aes(label = paste0(ifelse(pct < 1, "<1", round(pct,1)), "%")), 
              position = position_stack(vjust = 0.5), color = "white", size = 3) +
    facet_wrap(~ variable, scales = "free_y", ncol = 2) +
    coord_flip() +
    scale_fill_viridis_c(option = "plasma", name = "Pct (%)") +
    scale_y_continuous(expand = expansion(mult = c(0, 0.05))) +
    labs(title = "Grafico A7: Distribución de categorías — student_mat (top10 por variable; resto = Other)",
         x = NULL, y = "Conteo") +
    theme_minimal(base_size = 11) +
    theme(strip.text = element_text(face = "bold", size = 10),
          axis.text.y = element_text(size = 8),
          legend.position = "right")

  print(p)

  # Tabla de categorías de baja frecuencia (umbral: pct < 2% o n < 5)
  low_thresh_pct <- 2
  low_thresh_n <- 5
  low_counts <- counts2 %>%
    filter(pct < low_thresh_pct | n < low_thresh_n) %>%
    arrange(variable, pct)

  if (nrow(low_counts) > 0) {
    cat("\nCategorías de baja frecuencia (posibles atípicos):\n")
    low_counts %>%
      select(variable, value2, n, pct) %>%
      distinct() %>%
      knitr::kable(digits = 2, caption = "Categorías con baja frecuencia (student_mat)") %>%
      kableExtra::kable_styling(full_width = FALSE)
  } else {
    cat("\nNo se encontraron categorías de baja frecuencia según el umbral (pct < ", low_thresh_pct, "% o n < ", low_thresh_n, ").\n", sep = "")
  }
} else {
  cat("No hay variables categóricas en student_mat o el dataset está vacío.\n")
}
```

Gráfico de barras faceteado: distribución por categoría para cada variable categórica (se agrupan las categorías de baja frecuencia como "Other"). Útil para identificar valores atípicos y desbalances en las categorías.
De esta manera se puede visualizar que no existen variables atipicas en este conjunto de datos con respecto a las variables categoricas del dataset **student_mat**

## Resumen numérico: missing, Outlier and Correlation (student_por)

A continuació se genera un resumen numerico del dataset **student_por** reflejando estadisticamente valores que visualizan si es necesario imputar datos o limpiar registros en cuento a valores atipico o faltantes:

```{r por-numeric}
# Crear resumen numérico directamente a partir de student-por.csv
if (nrow(df_por) > 0) {
  num_sum_por <- df_por %>%
    select(where(is.numeric)) %>%
    summarise(across(everything(), list(
      mean = ~mean(.x, na.rm = TRUE),
      sd = ~sd(.x, na.rm = TRUE),
      median = ~median(.x, na.rm = TRUE),
      min = ~min(.x, na.rm = TRUE),
      max = ~max(.x, na.rm = TRUE),
      missing = ~sum(is.na(.x))
    ), .names = "{.col}_{.fn}"))

  # Convertir a formato largo para mostrar
  num_sum_por_long <- num_sum_por %>%
    pivot_longer(everything(), names_to = "metric", values_to = "value") %>%
    separate(metric, into = c("variable","stat"), sep = "_(?=[^_]+$)") %>%
    pivot_wider(names_from = stat, values_from = value) %>%
    arrange(variable)

  num_sum_por_long %>%
    kable(digits = 3, caption = "Tabla B5: Resumen numerico student_mat") %>%
    kable_styling(full_width = FALSE)
} else cat("Archivo student-mat.csv no encontrado o vacío.\n")
```

En el siguiente espacio se desea revisar toda la data **student_por** con el fin de determinar si existen valores faltantes y asi iniciar un procedimiento de imputación de datos:

```{r por-missing}
# Tabla de valores faltantes por variable (student_por) — mostrar solo variables con missing > 0
if (nrow(df_por) > 0) {
  missing_por <- df_por %>%
    summarise(across(everything(), ~sum(is.na(.)))) %>%
    pivot_longer(everything(), names_to = "variable", values_to = "missing") %>%
    arrange(desc(missing))

  missing_por_filtered <- missing_por %>% filter(missing > 0)

  if (nrow(missing_por_filtered) > 0) {
    missing_por_filtered %>%
      kable(digits = 0, caption = "Missing values — student_mat (solo variables con missing)") %>%
      kable_styling(full_width = FALSE)
  } else {
    cat("No se detectaron valores faltantes en student_mat.\n")
  }
} else cat("Archivo student-mat.csv no encontrado o vacío.\n")
```
Y como se puede visualizar el codigo arroja que la data no contiene valores faltantes, por lo que continuaremos con la sigueinte sesion.

### Boxplots y Correlación

A continuacion se grafican las variables numericas graficos **Boxplots** para visualizar las diferentes variables que presentan alguna posible variacion atipica en su conjunto de valores, como se pueden ver en las variables: Walc, traveltime, studytime, Medu, health, goout, G3, G2, G1, freetime, Fedu, famrel, failures, Dalc, age, y absences en la grafica B1:


```{r por_plots}
if (nrow(df_por)>0) {
  library(ggplot2)
  # Boxplots por variables numéricas
  nums <- df_por %>% select(where(is.numeric))
  if (ncol(nums) > 0) {
    nums_long <- nums %>% pivot_longer(everything(), names_to = "variable", values_to = "value")
    p2 <- ggplot(nums_long, aes(x = variable, y = value)) +
      geom_boxplot(outlier.size = 1, fill = "#74a9cf") +
      coord_flip() +
      labs(title = "Grafica B1: Boxplots variables numéricas (student_por)") +
      theme_minimal()
    print(p2)
  }
} else {
  cat("Archivo student-por.csv no encontrado o vacío.\n")
}
```

Aplicando la funcionalidad de detección de **Outliers** visualizamos en la sigueinte tabla (Tabla B4) la cantidad de valores que no se ajustan al rango o regla **IQR**.

```{r por-outliers}
# Detección de outliers por regla IQR para variables numéricas
if (nrow(df_por) > 0) {
  nums <- df_por %>% select(where(is.numeric))
  out_por <- map_dfr(names(nums), function(var) {
    x <- nums[[var]]
    if (all(is.na(x))) return(tibble(variable = var, outlier_count = 0))
    q1 <- quantile(x, 0.25, na.rm = TRUE)
    q3 <- quantile(x, 0.75, na.rm = TRUE)
    iqr <- q3 - q1
    lower <- q1 - 1.5 * iqr
    upper <- q3 + 1.5 * iqr
    tibble(variable = var, outlier_count = sum(x < lower | x > upper, na.rm = TRUE))
  })

  out_por %>% filter(outlier_count > 0) %>%
    kable(digits = 0, caption = "Tabla B4: Outliers detectados (IQR) — student_por") %>%
    kable_styling(full_width = FALSE)
} else cat("Archivo student-mat.csv no encontrado o vacío.\n")
```

En el siguiente grafico (Grafica B2) se realiza un grafico de correlación con las variables numericas con el fin de encontrar la posible relacion que puede existir en algunas variables tales como G1, G2, G3, Walc, Dalc, Fedu y Medu.

```{r por_correlacion}
if (nrow(df_por)>0) {
  library(ggplot2)
  # Mapa de correlación (numéricas)
  nums <- df_por %>% select(where(is.numeric))
  if (ncol(nums) >= 2) {
    cor_por <- cor(nums, use = "pairwise.complete.obs")
    cor_df <- as.data.frame(as.table(cor_por))
    p3 <- ggplot(cor_df, aes(Var1, Var2, fill = Freq)) +
      geom_tile() +
      scale_fill_gradient2(low = "blue", mid = "white", high = "red", midpoint = 0) +
      theme_minimal() +
      theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
      labs(title = "Grafica B2: Mapa de correlación (num) - student_por") +
      coord_fixed()
    print(p3)
  }
} else {
  cat("Archivo student-mat.csv no encontrado o vacío.\n")
}
```


Teniendo en cuenta aquellas que superan el parametro de correlaciones fuertes (|r|>=0.7) se tiene el siguiente listado:

```{r por-strong}
# Correlaciones fuertes |r| >= 0.7 (numéricas)
if (nrow(df_por) > 0) {
  nums <- df_por %>% select(where(is.numeric))
  strong_por <- tibble()
  if (ncol(nums) >= 2) {
    cor_por <- cor(nums, use = "pairwise.complete.obs")
    cor_df <- as.data.frame(as.table(cor_por))
    strong_por <- cor_df %>%
      filter(Var1 != Var2) %>%
      mutate(abs_r = abs(Freq)) %>%
      filter(abs_r >= 0.7) %>%
      arrange(desc(abs_r)) %>%
      rename(variable1 = Var1, variable2 = Var2, r = Freq) %>%
      select(variable1, variable2, r)
  }

  if (nrow(strong_por) > 0) {
    strong_por %>% kable(digits = 3, caption = "Tabla B3: Correlaciones fuertes (|r|>=0.7) — student_por") %>% kable_styling(full_width = FALSE)
  } else cat("No se detectaron correlaciones fuertes (|r|>=0.7) en variables numéricas.\n")
} else cat("Archivo student-mat.csv no encontrado o vacío.\n")
```

Para visualizar gráficamente las relaciones con mayor correlación (|r| notable), se muestran a continuación diagramas de dispersión entre G3 y cada variable relevante, junto con su línea de tendencia.

```{r por-scatter}
if (nrow(df_por)>0) {
  nums <- df_por %>% select(where(is.numeric))
  if ("G3" %in% names(nums) && ncol(nums) >= 2) {
    cor_with_G3 <- cor(nums, use = "pairwise.complete.obs")[, "G3", drop = FALSE]
    cor_with_G3 <- tibble(variable = rownames(cor_with_G3), corr = cor_with_G3[,1]) %>%
      filter(variable != "G3") %>%
      arrange(desc(abs(corr)))
    top_vars <- head(cor_with_G3$variable, 6)
    if (length(top_vars) > 0) {
      scatter_df <- df_por %>% select(all_of(c("G3", top_vars))) %>% pivot_longer(-G3, names_to = "variable", values_to = "value")
      p4 <- ggplot(scatter_df, aes(x = value, y = G3)) +
        geom_point(alpha = 0.6, size = 1.5, color = "#2b8cbe") +
        geom_smooth(method = "lm", se = FALSE, color = "red") +
        facet_wrap(~variable, scales = "free_x") +
        labs(title = "Grafico B6: G3 vs variables con mayor correlación (student_por)") +
        theme_minimal()
      print(p4)
    }
  }
} else cat("Archivo student-por.csv no encontrado o vacío.\n")
```

De los variables evaluadas, únicamente G1 y G2 alcanzan una correlación aceptable con la nota final (G3), por lo que se recomiendan como predictores prioritarios en la regresión lineal simple.

**Análisis Categorico**

Con el objetivo de analizar el comportamiento de las variables categóricas y detectar posibles valores atípicos, se presenta a continuación un gráfico que muestra la distribución de cada categoría.

```{r por-cat-bars-improved, fig.width=12, fig.height=10, echo=FALSE}
library(ggplot2)
library(forcats)
library(scales)
library(dplyr)

cat_vars <- df_por %>% select(where(~ is.character(.) || is.factor(.)))

if (nrow(df_por) > 0 && ncol(cat_vars) > 0) {

  # Long format y conteo inicial
  long_cat <- cat_vars %>%
    mutate(across(everything(), ~ as.character(.))) %>%
    pivot_longer(everything(), names_to = "variable", values_to = "value") %>%
    filter(!is.na(value))

  counts <- long_cat %>%
    group_by(variable, value) %>%
    summarise(n = n(), .groups = "drop") %>%
    group_by(variable) %>%
    arrange(variable, desc(n)) %>%
    mutate(rank = row_number()) %>%
    ungroup()

  # Agrupar categorías raras por variable (top 10 -> mostrar; resto -> "Other")
  counts2 <- counts %>%
    mutate(value2 = if_else(rank <= 10, value, "Other")) %>%
    group_by(variable, value2) %>%
    summarise(n = sum(n), .groups = "drop") %>%
    group_by(variable) %>%
    mutate(pct = n / sum(n) * 100) %>%
    ungroup()

  # Preparar factor reordenado dentro de cada facet
  counts2 <- counts2 %>%
    group_by(variable) %>%
    mutate(value2 = fct_reorder2(value2, n, n)) %>%
    ungroup()

  # Plot: barras horizontales por variable (faceteado)
  p <- ggplot(counts2, aes(x = value2, y = n, fill = pct)) +
    geom_col(width = 0.7, show.legend = TRUE) +
    geom_text(aes(label = paste0(ifelse(pct < 1, "<1", round(pct,1)), "%")), 
              position = position_stack(vjust = 0.5), color = "white", size = 3) +
    facet_wrap(~ variable, scales = "free_y", ncol = 2) +
    coord_flip() +
    scale_fill_viridis_c(option = "plasma", name = "Pct (%)") +
    scale_y_continuous(expand = expansion(mult = c(0, 0.05))) +
    labs(title = "Grafico B7: Distribución de categorías — student_por (top10 por variable; resto = Other)",
         x = NULL, y = "Conteo") +
    theme_minimal(base_size = 11) +
    theme(strip.text = element_text(face = "bold", size = 10),
          axis.text.y = element_text(size = 8),
          legend.position = "right")

  print(p)

  # Tabla de categorías de baja frecuencia (umbral: pct < 2% o n < 5)
  low_thresh_pct <- 2
  low_thresh_n <- 5
  low_counts <- counts2 %>%
    filter(pct < low_thresh_pct | n < low_thresh_n) %>%
    arrange(variable, pct)

  if (nrow(low_counts) > 0) {
    cat("\nCategorías de baja frecuencia (posibles atípicos):\n")
    low_counts %>%
      select(variable, value2, n, pct) %>%
      distinct() %>%
      knitr::kable(digits = 2, caption = "Categorías con baja frecuencia (student_mat)") %>%
      kableExtra::kable_styling(full_width = FALSE)
  } else {
    cat("\nNo se encontraron categorías de baja frecuencia según el umbral (pct < ", low_thresh_pct, "% o n < ", low_thresh_n, ").\n", sep = "")
  }
} else {
  cat("No hay variables categóricas en student_por o el dataset está vacío.\n")
}
```

Gráfico de barras faceteado: distribución por categoría para cada variable categórica (se agrupan las categorías de baja frecuencia como "Other"). Útil para identificar valores atípicos y desbalances en las categorías.
De esta manera se puede visualizar que no existen variables atipicas en este conjunto de datos con respecto a las variables categoricas del dataset **student_por**

## Histograma de la variable objetivo G3 (student_mat)

A continuación se construye un histograma de la variable objetivo (G3) para examinar su distribución y características principales (asimetría, multimodalidad, concentración y posibles valores extremos), con el fin de extraer conclusiones sobre su comportamiento antes del modelado.


```{r Mat_Histograma_G3, fig.width=8, fig.height=4}
if (nrow(df_mat) > 0 && "G3" %in% names(df_mat)) {
  library(ggplot2)
  g3 <- df_mat$G3
  g3 <- g3[!is.na(g3)]
  if (length(g3) > 1 && sd(g3) > 0) {
    mu <- mean(g3)
    sigma <- sd(g3)
    p1 <- ggplot(df_mat, aes(x = G3)) +
      geom_histogram(aes(y = ..density..), binwidth = 1, fill = "#2c7fb8", color = "white") +
      stat_function(fun = dnorm, args = list(mean = mu, sd = sigma), color = "red", size = 1) +
      geom_density(alpha = 0.15, fill = "red", color = NA) +  # opcional: densidad kernel
      labs(title = "Grafica A8: Distribución de G3 (student_mat)",
           subtitle = paste0("Normal ajustada: μ=", round(mu,2), ", σ=", round(sigma,2)),
           x = "G3", y = "Densidad") +
      theme_minimal()
    print(p1)
  } else {
    cat("G3 no tiene suficientes observaciones válidas o sd = 0.\n")
  }
} else {
  cat("Archivo student-mat.csv no encontrado, vacío o columna G3 ausente.\n")
}
```

**Estadísticos mostrados:** 
media ≈ 10.4, desviación estándar ≈ 4.6.

**Forma general:** distribución aproximadamente unimodal con pico alrededor de calificaciones entre 9–11; la campana normal ajustada aproxima bien el centro pero no captura totalmente los extremos.

**Desviaciones respecto a la normal:** presencia de valores muy bajos (cúmulo cercano a 0) y una cola derecha moderada — ligera asimetría/colas más pesadas que la normal.

**Implicaciones para modelado:** la normalidad no es perfecta pero suficiente como punto de partida; se deben validar residuos tras ajustar el modelo.

**Recomendaciones preliminares:** proceder con regresión lineal simple usando G3, para ello se debe revisar influencias (outliers), heterocedasticidad.


## Histograma de la variable objetivo G3 (student_por)
A continuación se construye un histograma de la variable objetivo (G3) para examinar su distribución y características principales (asimetría, multimodalidad, concentración y posibles valores extremos), con el fin de extraer conclusiones sobre su comportamiento antes del modelado.


```{r Por_Histograma_G3, fig.width=8, fig.height=4}
if (nrow(df_por) > 0 && "G3" %in% names(df_por)) {
  library(ggplot2)
  g3 <- df_por$G3
  g3 <- g3[!is.na(g3)]
  if (length(g3) > 1 && sd(g3) > 0) {
    mu <- mean(g3)
    sigma <- sd(g3)
    p1 <- ggplot(df_por, aes(x = G3)) +
      geom_histogram(aes(y = ..density..), binwidth = 1, fill = "#2c7fb8", color = "white") +
      stat_function(fun = dnorm, args = list(mean = mu, sd = sigma), color = "red", size = 1) +
      geom_density(alpha = 0.15, fill = "red", color = NA) +  # opcional: densidad kernel
      labs(title = "Grafica B8: Distribución de G3 (student_por)",
           subtitle = paste0("Normal ajustada: μ=", round(mu,2), ", σ=", round(sigma,2)),
           x = "G3", y = "Densidad") +
      theme_minimal()
    print(p1)
  } else {
    cat("G3 no tiene suficientes observaciones válidas o sd = 0.\n")
  }
} else {
  cat("Archivo student-por.csv no encontrado, vacío o columna G3 ausente.\n")
}
```

**Estadísticos mostrados:** 
media ≈ 11.9, desviación estándar ≈ 3.2.

**Forma general:** distribución aproximadamente unimodal con pico alrededor de calificaciones entre 10–11; la campana normal ajustada aproxima bien el centro pero no captura totalmente los extremos.

**Desviaciones respecto a la normal:** presencia de valores muy bajos (cúmulo cercano a 0) y una cola derecha moderada — ligera asimetría/colas más pesadas que la normal.

**Implicaciones para modelado:** la normalidad no es perfecta pero suficiente como punto de partida; se deben validar residuos tras ajustar el modelo.

**Recomendaciones preliminares:** proceder con regresión lineal simple usando G3, para ello se debe revisar influencias (outliers), heterocedasticidad.

## Conclusiones EDA 

Actualmente en el proyecto los datos no muestran valores faltantes (por lo que en un caso hipotetico **median_imputed** y **mice_pooled** no aportarían cambios útiles). Existen outliers detectados por IQR y si se buscara es reducir su influencia en la regresión sin eliminar observaciones ni introducir demasiada suposición **Winsorizar** conservaría el tamaño de la muestra y reduciría el sesgo que los extremos causaría en estimadores basados en la media y en OLS (Ordinary Least Squares / Mínimos Cuadrados Ordinarios)

Ahora, para el caso que estamos estudiando de las calificaciones de los estudiantes y la prediccion de la variable de salida G3, ¿Es necesario imputar datos?, ¿Son realmente los valores atipicos valores regularmente no dados o imposibles de obtener en las calificaciones?

Segun el documento de investigacion https://repositorium.sdum.uminho.pt/bitstream/1822/8024/1/student.pdf la calificación posible de un alumno oscila desde 0 hasta 20, y basado en el análisis exploratorio realizado, se concluye que:

**Calidad de los datos:** Las base de datos `student_mat` y `student_por` se encuentran limpia, sin valores faltantes relevantes y los valores extremos detectados corresponden a calificaciones plausibles dentro del rango académico 0-20, por lo que no requieren imputación o eliminación.

**Variables objetivo y predictores:** La variable `G3` (nota final) en amabos datasets presentan una distribución aproximadamente unimodal con ligera asimetría, siendo adecuada para modelado con regresión lineal. Las variables `G1` y `G2` en ambos datasets igualmente mostraron correlaciones más altas con `G3`, identificándose como los predictores más prometedores.

**Preparación para modelado:** Los datos están listos para proceder con la aplicación de un modelo de regresión lineal simple, donde se evaluará la relación entre las notas previas y la calificación final.

### Comparación entre datasets

```{r compare-summary}
# dimensiones y conteos de missing
mat_missing_total <- if (nrow(df_mat) > 0) sum(is.na(df_mat)) else NA
por_missing_total <- if (nrow(df_por) > 0) sum(is.na(df_por)) else NA

mat_dims <- if (nrow(df_mat) > 0) dim(df_mat) else c(NA,NA)
por_dims <- if (nrow(df_por) > 0) dim(df_por) else c(NA,NA)

comp_tab <- tibble(
  dataset = c("student_mat","student_por"),
  rows = c(mat_dims[1], por_dims[1]),
  cols = c(mat_dims[2], por_dims[2]),
  total_missing = c(mat_missing_total, por_missing_total)
)

comp_tab %>% kable(caption = "Comparación resumida entre datasets") %>% kable_styling(full_width = FALSE)
```


# Definición: Modelo de Regresión Lienal Simple (SLMR)

La **regresión lineal simple** es una técnica estadística que modela la relación lineal entre dos variables cuantitativas: una variable independiente o predictora (X) y una variable dependiente o respuesta (Y). Su objetivo es encontrar la mejor línea recta que describa la relación entre estas variables y permita realizar predicciones.

## Modelo Matemático

El modelo de regresión lineal simple se expresa mediante la ecuación:

$$Y_i = \beta_0 + \beta_1 X_i + \varepsilon_i$$

Donde:
- $Y_i$ = variable dependiente (respuesta) para la observación i
- $X_i$ = variable independiente (predictora) para la observación i  
- $\beta_0$ = intercepto (ordenada al origen)
- $\beta_1$ = pendiente (coeficiente de regresión)
- $\varepsilon_i$ = término de error aleatorio

## Estimación por Mínimos Cuadrados Ordinarios (OLS)

Los parámetros $\beta_0$ y $\beta_1$ se estiman minimizando la suma de cuadrados de los residuos:

$$\min \sum_{i=1}^{n} (Y_i - \hat{Y_i})^2 = \min \sum_{i=1}^{n} (Y_i - \beta_0 - \beta_1 X_i)^2$$

Las fórmulas de estimación son:

$$\hat{\beta_1} = \frac{\sum_{i=1}^{n}(X_i - \bar{X})(Y_i - \bar{Y})}{\sum_{i=1}^{n}(X_i - \bar{X})^2}$$

$$\hat{\beta_0} = \bar{Y} - \hat{\beta_1}\bar{X}$$

## Supuestos del Modelo

Para que la regresión lineal simple sea válida, deben cumplirse los siguientes supuestos:

1. **Linealidad**: La relación entre X e Y es lineal
2. **Independencia**: Las observaciones son independientes
3. **Homocedasticidad**: La varianza de los errores es constante
4. **Normalidad**: Los errores siguen una distribución normal
5. **No multicolinealidad**: (No aplica en regresión simple)

## Métricas de Evaluación

- **Coeficiente de Determinación (R²)**: Proporción de variabilidad de Y explicada por X
  $$R^2 = \frac{\text{Variabilidad Explicada}}{\text{Variabilidad Total}} = \frac{SSR}{SST}$$

- **Error Estándar Residual**: Medida de dispersión de los residuos
  $$s = \sqrt{\frac{\sum_{i=1}^{n}(Y_i - \hat{Y_i})^2}{n-2}}$$

## Interpretación de Coeficientes

- **$\hat{\beta_0}$**: Valor esperado de Y cuando X = 0
- **$\hat{\beta_1}$**: Cambio promedio en Y por cada unidad de incremento en X


# Aplicación: Regresión Lineal Simple (student_mat)

En nuestro análisis del dataset `student_mat`, aplicamos regresión lineal simple para modelar la relación entre las calificaciones previas (G1 o G2) y la nota final (G3), permitiendo predecir el rendimiento académico final basado en el desempeño previo del estudiante.


## Selección de Variables Predictoras

Se identifican y seleccionan las variables con mayor poder predictivo basándose en las correlaciones calculadas en el EDA. Este paso es fundamental para construir un modelo moderado y efectivo.

```{r slr-variable-selection, results='asis'}
# Selección de variables predictoras basada en correlación con G3
if (nrow(df_mat) > 0) {
  library(dplyr)
  library(knitr)
  
  # Calcular correlaciones con G3 para todas las variables numéricas
  nums <- df_mat %>% select(where(is.numeric))
  
  if ("G3" %in% names(nums)) {
    cor_with_g3 <- cor(nums, use = "pairwise.complete.obs")[, "G3", drop = FALSE]
    
    # Crear tabla ordenada de correlaciones
    cor_table <- tibble(
      variable = rownames(cor_with_g3),
      correlacion = as.numeric(cor_with_g3[,1])
    ) %>%
      filter(variable != "G3") %>%
      arrange(desc(abs(correlacion))) %>%
      mutate(
        correlacion = round(correlacion, 4),
        abs_correlacion = round(abs(correlacion), 4)
      )
    
    # Mostrar tabla de correlaciones
    cor_table %>%
      head(10) %>%
      kable(caption = "Tabla 7.1: Variables numéricas ordenadas por correlación con G3", 
            format = "html") %>%
      kable_styling(full_width = FALSE, bootstrap_options = c("striped", "hover", "condensed")) %>%
      cat()
    
    # Identificar el mejor predictor
    best_predictor <- cor_table$variable[1]
    best_correlation <- cor_table$correlacion[1]
    
    cat("\n Por lo tanto, la variable seleccionada para la regresión es:", best_predictor, 
        "\n con una correlación de:", round(best_correlation, 4), "\n con respecto a G3")
  }
} else {
  cat("Dataset student_mat no disponible para análisis.")
}
```

## Visualización de la Relación Lineal

Antes del ajuste formal, se explora visualmente la relación entre el predictor seleccionado y la variable objetivo para confirmar la adequacidad de un modelo lineal y identificar posibles patrones o valores influyentes.

```{r slr-scatter-plot, fig.width=8, fig.height=6, results='asis'}
# Gráfico de dispersión con línea de tendencia
if (nrow(df_mat) > 0 && exists("best_predictor")) {
  library(ggplot2)
  
  # Crear el gráfico de dispersión
  p_scatter <- ggplot(df_mat, aes_string(x = best_predictor, y = "G3")) +
    geom_point(alpha = 0.6, size = 2, color = "#2b8cbe") +
    geom_smooth(method = "lm", se = TRUE, color = "red", fill = "pink", alpha = 0.3) +
    labs(
      title = paste("Gráfico 7.1: Relación entre", best_predictor, "y G3"),
      subtitle = paste("Correlación r =", round(best_correlation, 4)),
      x = paste(best_predictor, "(Variable Predictora)"),
      y = "G3 (Nota Final)"
    ) +
    theme_minimal() +
    theme(
      plot.title = element_text(size = 14, face = "bold"),
      plot.subtitle = element_text(size = 12),
      axis.title = element_text(size = 11)
    )
  
  print(p_scatter)
  
  # Estadísticas descriptivas de ambas variables
  stats_table <- df_mat %>%
    select(all_of(c(best_predictor, "G3"))) %>%
    summarise(
      across(everything(), list(
        n = ~sum(!is.na(.)),
        media = ~round(mean(., na.rm = TRUE), 2),
        sd = ~round(sd(., na.rm = TRUE), 2),
        min = ~min(., na.rm = TRUE),
        max = ~max(., na.rm = TRUE)
      ), .names = "{.col}_{.fn}")
    ) %>%
    pivot_longer(everything(), names_to = "stat", values_to = "value") %>%
    separate(stat, into = c("variable", "estadistico"), sep = "_(?=[^_]+$)") %>%
    pivot_wider(names_from = estadistico, values_from = value)
  
  stats_table %>%
    kable(
      caption = "Tabla 7.2: Estadísticas descriptivas de las variables del modelo", 
      format = "html"
    ) %>%
    kable_styling(
      full_width = FALSE, 
      bootstrap_options = c("striped", "hover", "condensed")
    ) %>%
    cat()
  
} else {
  cat("No se puede generar el gráfico: datos o predictor no disponibles.")
}
```

## Ajuste del Modelo de Regresión Lineal Simple

Se ajusta el modelo de regresión lineal simple utilizando mínimos cuadrados ordinarios (OLS) y se extraen los coeficientes principales junto con sus medidas de significancia estadística.

```{r slr-model-fit, results='asis'}
# Ajuste del modelo de regresión lineal simple
if (nrow(df_mat) > 0 && exists("best_predictor")) {
  library(broom)
  
  # Crear fórmula del modelo
  formula_str <- paste("G3 ~", best_predictor)
  model_formula <- as.formula(formula_str)
  
  # Ajustar el modelo
  slr_model <- lm(model_formula, data = df_mat)
  
  # Resumen del modelo
  model_summary <- summary(slr_model)
  
  # Extraer coeficientes usando broom para formato tidy
  coefficients_table <- tidy(slr_model) %>%
    mutate(
      estimate = round(estimate, 4),
      std.error = round(std.error, 4),
      statistic = round(statistic, 3),
      p.value = ifelse(p.value < 0.001, "< 0.001", round(p.value, 4))
    ) %>%
    rename(
      Término = term,
      Coeficiente = estimate,
      `Error Estándar` = std.error,
      `Estadístico t` = statistic,
      `Valor p` = p.value
    )
  
  # Mostrar tabla de coeficientes
  coefficients_table %>%
    kable(
      caption = "Tabla 7.3: Coeficientes del modelo de regresión lineal simple", 
      format = "html"
    ) %>%
    kable_styling(
      full_width = FALSE, 
      bootstrap_options = c("striped", "hover", "condensed")
    ) %>%
    cat()
  
  # Métricas de bondad de ajuste
  model_metrics <- tibble(
    Métrica = c("R-cuadrado", "R-cuadrado ajustado", "Error estándar residual", "Estadístico F", "Valor p del modelo"),
    Valor = c(
      round(model_summary$r.squared, 4),
      round(model_summary$adj.r.squared, 4),
      round(model_summary$sigma, 4),
      round(model_summary$fstatistic[1], 3),
      ifelse(
        pf(model_summary$fstatistic[1], 
           model_summary$fstatistic[2], 
           model_summary$fstatistic[3], 
           lower.tail = FALSE) < 0.001, 
        "< 0.001", 
        round(pf(model_summary$fstatistic[1], 
                 model_summary$fstatistic[2], 
                 model_summary$fstatistic[3], 
                 lower.tail = FALSE), 4)
      )
    )
  )
  
  model_metrics %>%
    kable(
      caption = "Tabla 7.4: Métricas de bondad de ajuste del modelo", 
      format = "html"
    ) %>%
    kable_styling(
      full_width = FALSE, 
      bootstrap_options = c("striped", "hover", "condensed")
    ) %>%
    cat()
  
  # Ecuación del modelo
  intercept <- round(coefficients(slr_model)[1], 4)
  slope <- round(coefficients(slr_model)[2], 4)
  
  cat("\n**Ecuación del modelo ajustado:**")
  cat("\nG3 =", intercept, "+", slope, "×", best_predictor)
  cat("\n\n**Interpretación:**")
  cat("\n- Por cada unidad adicional en", best_predictor, ", G3 aumenta en promedio", slope, "puntos")
  cat("\n- El modelo explica", round(model_summary$r.squared * 100, 2), "% de la variabilidad en G3")
  
} else {
  cat("No se puede ajustar el modelo: datos o predictor no disponibles.")
}
```

## Validación de Supuestos del Modelo

Se verifican los supuestos fundamentales de la regresión lineal: linealidad, homocedasticidad, normalidad de residuos e independencia. Esta validación es crucial para confirmar la validez de las inferencias estadísticas.

### Calcular residuos y valores ajustados

```{r slr-assumptions1}
# Validación de supuestos del modelo
if (exists("slr_model")) {
  library(ggplot2)
  library(gridExtra)
  
  # Calcular residuos y valores ajustados
  model_data <- augment(slr_model)
  
  # 1. Gráfico de residuos vs valores ajustados (homocedasticidad y linealidad)
    ggplot(model_data, aes(x = .fitted, y = .resid)) +
    geom_point(alpha = 0.6, color = "#2b8cbe") +
    geom_hline(yintercept = 0, color = "red", linetype = "dashed") +
    geom_smooth(method = "loess", se = FALSE, color = "orange") +
    labs(
      title = "Grafico 4.4.1: Residuos vs Valores Ajustados",
      subtitle =  paste("n =", nrow(model_data), "observaciones, Evaluación de linealidad y homocedasticidad"),
      x = "Valores Ajustados",
      y = "Residuos"
    ) +
    theme_minimal()
}
``` 

#### Análisis del Gráfico de Residuos vs Valores Ajustados

- **Distribución centrada en cero:** Los residuos se distribuyen alrededor de la línea horizontal en y = 0 (línea roja punteada), lo que indica que el modelo no presenta sesgo sistemático en sus predicciones.
- **Patrón relativamente aleatorio:** No se observa una estructura clara o patrón curvilíneo pronunciado en los residuos, sugiriendo que el supuesto de linealidad se cumple razonablemente bien.
- **Ausencia de heterocedasticidad severa:** La dispersión de los residuos no muestra un patrón de embudo marcado (aumentando o disminuyendo sistemáticamente), indicando que la varianza de los errores es relativamente constante (homocedasticidad).

#### Observaciones que Requieren Atención:

- **Ligera curvatura en la línea LOESS:** La línea naranja **LOcally wEighted Scatterplot Smoothing** (suavizado LOESS) muestra una leve curvatura, especialmente en los extremos, sugiriendo que puede existir una pequeña no-linealidad que el modelo lineal simple no está capturando completamente.
- **Presencia de valores extremos:** Se observan algunos residuos con valores absolutos superiores a 5 y hasta cerca de -10, indicando la presencia de observaciones con residuos grandes que podrían ser influyentes.
- **Distribución no perfectamente uniforme:** Existe una ligera concentración de puntos en la región central (valores ajustados entre 8-15), lo que es típico pero podría afectar la precisión en los extremos del rango.
- **Interpretación para el Modelo G3 ~ G2:** El gráfico sugiere que el modelo de regresión lineal simple es generalmente apropiado para estos datos, con las siguientes consideraciones:

El modelo captura adecuadamente la relación principal entre G2 y G3
Los supuestos de linealidad y homocedasticidad se cumplen aceptablemente
Existen algunas observaciones atípicas que podrían beneficiarse de un análisis más detallado
La ligera curvatura observada podría indicar que un modelo con un término cuadrático o la inclusión de variables adicionales podría mejorar el ajuste

#### Recomendación:
El modelo actual es válido y útil para predicción, pero se recomienda:

- Identificar y examinar las observaciones con residuos extremos

- Considerar la inclusión de variables predictoras adicionales si están disponibles

- Evaluar si transformaciones de las variables mejoran el ajuste

En conjunto, este análisis respalda la robustez del modelo ajustado y su capacidad para hacer predicciones confiables de las calificaciones finales (G3) basadas en las calificaciones del segundo período (G2).

### Calcular Q-Q plot para normalidad de residuos
  
```{r slr-assumptions2}
# Validación de supuestos del modelo
if (exists("slr_model")) {
  library(ggplot2)
  library(gridExtra)

  # 2. Q-Q plot para normalidad de residuos
  ggplot(model_data, aes(sample = .resid)) +
    stat_qq(alpha = 0.6, color = "#2b8cbe") +
    stat_qq_line(color = "red") +
    labs(
      title = "Grafica 4.4.2.1: Q-Q Plot de Residuos",
      subtitle = "Evaluación de normalidad",
      x = "Cuantiles Teóricos",
      y = "Cuantiles de Residuos"
    ) +
    theme_minimal()
 }
```

#### Análisis del Q-Q Plot de Residuos

**Seguimiento general de la línea teórica:** 

La mayoría de los puntos (aproximadamente 80-85%) se alinean bien con la línea roja diagonal, indicando que los residuos se aproximan razonablemente a una distribución normal.

**Comportamiento central adecuado:** 

En la región central del gráfico (cuantiles teóricos entre -1 y +1), los puntos siguen muy de cerca la línea de referencia, lo cual es una buena señal para la normalidad.

#### Desviaciones Observadas:

- **Colas pesadas en extremos inferiores:** En el extremo izquierdo (cuantiles teóricos < -2), los puntos se desvían por debajo de la línea roja, formando una curva que indica residuos más extremos de lo esperado en la cola inferior.
- **Ligera desviación en cola superior:**  En el extremo derecho (cuantiles teóricos > +2), hay algunos puntos que se alejan ligeramente por encima de la línea, aunque esta desviación es menos pronunciada.
- **Patrón de "S" sutil:** La forma general sugiere una ligera desviación de la normalidad con colas más pesadas que una distribución normal estándar.

#### Interpretación Estadística:

**Implicaciones para el modelo:**
Los residuos NO siguen perfectamente una distribución normal, especialmente en los extremos
La desviación es más pronunciada en valores negativos extremos, lo que corresponde a observaciones donde el modelo sobrestima significativamente la nota real.

El centro de la distribución es aproximadamente normal, lo que es positivo para la mayoría de las predicciones
Impacto en las inferencias:

- **Intervalos de confianza y pruebas t:** Pueden ser menos precisos, especialmente para predicciones en los extremos.
- **Validez del modelo:**  El modelo sigue siendo útil, pero con ciertas limitaciones en las colas
- **Robustez:** Para tamaños de muestra grandes (como este caso), las inferencias siguen siendo relativamente robustas

**Recomendaciones:**
El modelo es aceptable para uso práctico, pero se recomienda:

- Identificar y examinar las observaciones con residuos extremos

- Considerar la inclusión de variables predictoras adicionales si están disponibles

- Evaluar si transformaciones de las variables mejoran el ajuste

En conjunto, este análisis respalda la robustez del modelo ajustado y su capacidad para hacer predicciones confiables de las calificaciones finales (G3) basadas en las calificaciones del segundo período (G2).

### Histograma de Residuos

```{r slr-assumptions3}
if (exists("slr_model")) {
  library(ggplot2) 
  # 3. Histograma de residuos
  ggplot(model_data, aes(x = .resid)) +
    geom_histogram(aes(y = after_stat(density)), bins = 20, 
                   fill = "#2b8cbe", alpha = 0.7, color = "white") +
    geom_density(color = "red", linewidth = 1) +
    stat_function(fun = dnorm, 
                  args = list(mean = mean(model_data$.resid), 
                             sd = sd(model_data$.resid)),
                  color = "orange", linetype = "dashed", linewidth = 1) +
    labs(title = "Grafica 4.4.3.1: Distribución de Residuos",
         subtitle = "Comparación con distribución normal",
         x = "Residuos",
         y = "Densidad"
    ) +
    theme_minimal()
 }
```

#### Análisis del Histograma de Residuos

- **Distribución aproximadamente simétrica**: El histograma muestra una forma general simétrica centrada alrededor de cero, lo cual es consistente con el supuesto de que los residuos deben tener media cero.

- **Forma unimodal**: Se observa un único pico en la distribución, indicando que no hay mezclas de poblaciones o múltiples procesos generadores de errores.

- **Concentración central apropiada**: La mayor densidad de residuos se encuentra en el rango [-2, +2], lo que es esperado para residuos que siguen aproximadamente una distribución normal.

#### Desviaciones Observadas:

- **Diferencia entre curvas**: La **línea roja sólida** (densidad kernel estimada de los residuos) no coincide perfectamente con la **línea naranja punteada** (distribución normal teórica), especialmente en los extremos y en el pico central.

- **Pico más pronunciado**: La distribución empírica (roja) muestra un pico más alto y estrecho que la distribución normal teórica, sugiriendo una **mayor concentración de valores cerca de cero** de lo que predice la normal.

- **Colas más ligeras en algunos puntos**: En ciertos rangos, la distribución empírica muestra menos densidad que la normal teórica, aunque esto es menos evidente que el pico central más pronunciado.

- **Ligera asimetría sutil**: Aunque visualmente simétrica, se puede observar una muy leve diferencia en las colas, consistente con lo observado en el Q-Q plot.

#### Comparación de distribuciones:
- **Histograma (barras azules)**: Muestra la distribución empírica real de los residuos
- **Curva roja sólida**: Estimación suavizada (kernel) de la densidad empírica
- **Curva naranja punteada**: Distribución normal teórica con la misma media y desviación estándar

#### Implicaciones para el modelo:
- **Los residuos se aproximan razonablemente a la normalidad** en términos generales
- **Existe una ligera leptocurtosis** (mayor concentración central), indicando que el modelo genera errores más predecibles en el centro del rango
- **La forma general es apropiada** para mantener la validez de las inferencias estadísticas

#### Fortalezas del modelo:
- La distribución centrada en cero confirma que el modelo no tiene sesgo sistemático
- La forma general unimodal y simétrica respalda la adequacidad del modelo lineal
- La concentración central sugiere que la mayoría de las predicciones son bastante precisas

#### Limitaciones identificadas:
- La mayor concentración central podría indicar que el modelo es ligeramente conservador en sus predicciones
- Las diferencias con la normal teórica sugieren que los intervalos de confianza podrían ser ligeramente imprecisos en los extremos

#### Conclusión de histograma de residuos:

El histograma de residuos **confirma la viabilidad del modelo de regresión lineal simple** para este dataset. Aunque existen ligeras desviaciones de la normalidad perfecta, estas son **menores y no comprometen la validez fundamental** del modelo.

### Gráfico de distancia de Cook
```{r slr-assumptions4}
if (exists("slr_model")) {
  library(ggplot2) 
  # 4. Gráfico de distancia de Cook
  ggplot(model_data, aes(x = seq_along(.cooksd), y = .cooksd)) +
    geom_point(alpha = 0.6, color = "#2b8cbe") +
    geom_hline(yintercept = 4/nrow(model_data), 
               color = "red", linetype = "dashed") +
    labs(
      title = "Grafica 4.4.4.1: Distancia de Cook",
      subtitle = "Identificación de observaciones influyentes",
      x = "Índice de Observación",
      y = "Distancia de Cook"
    ) +
    theme_minimal()
 }
```

#### Gráfico de distancia de Cook

- **Mayoría de observaciones dentro del rango normal**: La gran mayoría de los puntos se concentran cerca de cero (por debajo de 0.01), indicando que la mayoría de las observaciones tienen poca influencia individual en los coeficientes del modelo.

- **Distribución esperada**: El patrón general muestra la típica distribución de distancias de Cook, con muchas observaciones de baja influencia y pocas observaciones con valores más altos.

- **Línea de referencia clara**: La línea roja punteada horizontal (umbral = 4/n ≈ 0.01) proporciona un criterio objetivo para identificar observaciones potencialmente influyentes.

#### Observaciones que Requieren Atención:

- **Presencia de observaciones por encima del umbral**: Se observan varios puntos que superan la línea de referencia roja (4/n), con valores de distancia de Cook entre 0.01 y aproximadamente 0.035, indicando **observaciones moderadamente influyentes**.

- **Concentración de observaciones influyentes**: Las observaciones con mayor distancia de Cook se distribuyen a lo largo de todo el dataset (índices desde ~50 hasta ~350), sugiriendo que no están concentradas en una región específica de los datos.

- **Valores máximos moderados**: Aunque hay observaciones influyentes, ninguna presenta valores extremadamente altos (>0.1), lo que sería una señal de alarma mayor.

#### Criterio de evaluación:
- **Umbral conservador**: 4/n ≈ 0.01 (línea roja punteada)
- **Umbral moderado**: 1 (no se alcanza en este gráfico)
- **Observaciones influyentes identificadas**: Aproximadamente 15-20 observaciones superan el umbral conservador

##### Implicaciones para el modelo:
- Las observaciones con distancia de Cook elevada **podrían estar afectando ligeramente** los coeficientes estimados
- **La influencia es moderada**, no extrema, por lo que los coeficientes siguen siendo confiables
- **Eliminar estas observaciones podría cambiar los coeficientes**, pero probablemente no de manera dramática

#### Impacto en las predicciones:
- **Las predicciones generales del modelo son robustas** a la presencia de estas observaciones
- **Los intervalos de confianza y predicción mantienen validez** general
- **La capacidad predictiva del modelo no se ve comprometida** significativamente

#### Recomendaciones Específicas:

- **Investigación de observaciones influyentes**: Examinar las observaciones con mayor distancia de Cook para identificar:
   - Patrones comunes (características demográficas, académicas, etc.)
   - Posibles errores de entrada de datos
   - Casos genuinamente atípicos pero válidos

- **Análisis de sensibilidad**: Ejecutar el modelo excluyendo las observaciones más influyentes para evaluar:
   - Cambios en los coeficientes estimados
   - Variaciones en R² y otras métricas de ajuste
   - Estabilidad de las conclusiones principales

- **Validación del modelo**: 
   - **Mantener las observaciones** si representan variabilidad natural del fenómeno
   - **Documentar la presencia** de estas observaciones en el informe final
   - **No eliminar automáticamente** sin justificación sustantiva

#### Conclusión de Gráfico de distancia de Cook

El gráfico de distancia de Cook **confirma que el modelo es generalmente robusto** y no está dominado por observaciones atípicas extremas. Aunque se identifican algunas observaciones moderadamente influyentes, estas **no comprometen la validez fundamental del modelo**.

### Pruebas estadísticas de supuestos:

#### Test de Shapiro-Wilk para normalidad (si n <= 5000)
```{r slr-validations1}

if (exists("slr_model")) {  
  # Test de Shapiro-Wilk para normalidad (si n <= 5000)
  if (length(residuals(slr_model)) <= 5000) {
    shapiro_test <- shapiro.test(residuals(slr_model))
    cat("Normalidad de residuos (Shapiro-Wilk):")
    cat("\n  W =", round(shapiro_test$statistic, 4))
    cat("\n  p-valor =", ifelse(shapiro_test$p.value < 0.001, "< 0.001", round(shapiro_test$p.value, 4)))
    cat("\n  Interpretación:", ifelse(shapiro_test$p.value > 0.05, "No rechazar normalidad", "Rechazar normalidad"))
  }
  
} else {
  cat("Modelo no disponible para validación de supuestos.")
}
```
##### Consideraciones del test Shapiro-Wilk
```{r}

# En tu código, podrías usar:
if (shapiro_test$p.value > 0.05) {
  cat("✓ Supuesto de normalidad CUMPLIDO")
} else if (shapiro_test$statistic > 0.90) {
  cat("⚠ Ligera desviación de normalidad - ACEPTABLE para uso práctico")
} else {
  cat("✗ Desviación significativa - CONSIDERAR transformaciones")
}
```

#### Test de Breusch-Pagan para homocedasticidad (requiere lmtest)
```{r slr-validation2}
if (exists("slr_model")) {  
  
  # Test de Breusch-Pagan para homocedasticidad (requiere lmtest)
  if (requireNamespace("lmtest", quietly = TRUE)) {
    library(lmtest)
    bp_test <- bptest(slr_model)
    cat("Homocedasticidad (Breusch-Pagan):")
    cat("\n  BP =", round(bp_test$statistic, 4))
    cat("\n  p-valor =", ifelse(bp_test$p.value < 0.001, "< 0.001", round(bp_test$p.value, 4)))
    cat("\n  Interpretación:", ifelse(bp_test$p.value > 0.05, "No rechazar homocedasticidad", "Rechazar homocedasticidad"))
  }
} else {
  cat("Modelo no disponible para validación de supuestos.")
}
```

#### Identificar observaciones influyentes

```{r validation3}
if (exists("slr_model")) {

  # Identificar observaciones influyentes
  influential_obs <- which(model_data$.cooksd > 4/nrow(model_data))
  
  if (length(influential_obs) > 0) {
    cat("Observaciones influyentes (Distancia de Cook > 4/n):")
    cat("\n  Observaciones:", paste(influential_obs, collapse = ", "))
    cat("\n  Total:", length(influential_obs), "de", nrow(model_data), "observaciones")
  } else {
    cat("\n\nNo se encontraron observaciones influyentes significativas.")
  }
  
} else {
  cat("Modelo no disponible para validación de supuestos.")
}
```

## Análisis de Residuos

Se realiza un análisis detallado de los residuos para evaluar la calidad del ajuste y se generan predicciones con sus respectivos intervalos de confianza.

```{r slr-predictions, results='asis'}
# Análisis de residuos y predicciones
if (exists("slr_model")) {
  
  # Estadísticas de residuos
  residuos <- residuals(slr_model)
  residuos_stats <- tibble(
    Estadística = c("Media", "Desviación Estándar", "Mínimo", "Q1", "Mediana", "Q3", "Máximo"),
    Valor = c(
      round(mean(residuos), 4),
      round(sd(residuos), 4),
      round(min(residuos), 4),
      round(quantile(residuos, 0.25), 4),
      round(median(residuos), 4),
      round(quantile(residuos, 0.75), 4),
      round(max(residuos), 4)
    )
  )
  
  residuos_stats %>%
    kable(caption = "Tabla 7.5: Estadísticas descriptivas de los residuos", 
          format = "html") %>%
    kable_styling(full_width = FALSE, 
                  bootstrap_options = c("striped", "hover", "condensed")) %>%
    cat()
  
  # Generar predicciones con intervalos de confianza
  pred_data <- tibble(!!sym(best_predictor) := seq(min(df_mat[[best_predictor]], na.rm = TRUE),
                                                    max(df_mat[[best_predictor]], na.rm = TRUE),
                                                    length.out = 50))
  
  predictions <- predict(slr_model, newdata = pred_data, interval = "confidence", level = 0.95)
  pred_results <- bind_cols(pred_data, as_tibble(predictions))
  
  # Gráfico de predicciones con intervalos de confianza
  p_pred <- ggplot() +
    # Datos originales
    geom_point(data = df_mat, aes_string(x = best_predictor, y = "G3"), 
               alpha = 0.6, size = 2, color = "#2b8cbe") +
    # Línea de regresión
    geom_line(data = pred_results, aes_string(x = best_predictor, y = "fit"), 
              color = "red", size = 1) +
    # Intervalos de confianza
    geom_ribbon(data = pred_results, aes_string(x = best_predictor, ymin = "lwr", ymax = "upr"), 
                alpha = 0.2, fill = "red") +
    labs(
      title = "Gráfico 7.3: Modelo ajustado con intervalos de confianza",
      subtitle = paste("IC del 95% para la media de G3 dado", best_predictor),
      x = paste(best_predictor, "(Variable Predictora)"),
      y = "G3 (Nota Final)"
    ) +
    theme_minimal() +
    theme(
      plot.title = element_text(size = 14, face = "bold"),
      plot.subtitle = element_text(size = 12)
    )
  
  print(p_pred)
  
  # Tabla de predicciones ejemplo
  ejemplo_valores <- c(
    round(quantile(df_mat[[best_predictor]], c(0.1, 0.25, 0.5, 0.75, 0.9), na.rm = TRUE))
  )
  
  pred_ejemplo <- predict(slr_model, 
                          newdata = tibble(!!sym(best_predictor) := ejemplo_valores), 
                          interval = "prediction", level = 0.95)
  
  ejemplo_table <- tibble(
    !!sym(paste(best_predictor, "(Valor)")) := ejemplo_valores,
    `G3 Predicho` = round(pred_ejemplo[,"fit"], 2),
    `Límite Inferior (95%)` = round(pred_ejemplo[,"lwr"], 2),
    `Límite Superior (95%)` = round(pred_ejemplo[,"upr"], 2)
  )
  
  ejemplo_table %>%
    kable(caption = paste("Tabla 7.6: Ejemplos de predicción con intervalos del 95%"), 
          format = "html") %>%
    kable_styling(full_width = FALSE, 
                  bootstrap_options = c("striped", "hover", "condensed")) %>%
    cat()
  
} else {
  cat("Modelo no disponible para generar predicciones.")
}
```


dado las violaciones anteriores a los supuestos, se procede con la implementacion de transformaciones:

## Analisis de transformaciones

```{r transformations-analysis, results='asis'}
# PASO 1: TRANSFORMACIONES PARA MEJORAR EL MODELO

cat(paste(rep("", 40), collapse = ""), "\n\n")

# 1.1 Explorar diferentes transformaciones de G3
if (nrow(df_mat) > 0 && exists("best_predictor")) {
  library(forecast)
  library(purrr)  # Asegurar que purrr esté cargado para map_dfr
  
  # Crear dataset con transformaciones
  df_trans <- df_mat %>%
    filter(G3 > 0, !is.na(G3), !is.na(.data[[best_predictor]])) %>%
    mutate(
      G3_original = G3,
      G3_log = log(G3),
      G3_sqrt = sqrt(G3),
      G3_cuadrada = G3^2
    )
  
  # Transformación Box-Cox
  if (min(df_trans$G3) > 0) {
    lambda_bc <- BoxCox.lambda(df_trans$G3)
    df_trans$G3_boxcox <- BoxCox(df_trans$G3, lambda_bc)
    cat("Lambda óptimo Box-Cox:", round(lambda_bc, 4), "\n\n")
  }
  
  # Lista de transformaciones a probar
  transformaciones <- c("G3_original", "G3_log", "G3_sqrt", "G3_boxcox")
  
  # Crear lista vacía para resultados
  resultados_lista <- list()
  
  # Iterar sobre transformaciones
  for (i in seq_along(transformaciones)) {
    trans_var <- transformaciones[i]
    
    if (trans_var %in% names(df_trans)) {
      # Ajustar modelo
      formula_trans <- as.formula(paste(trans_var, "~", best_predictor))
      modelo_trans <- lm(formula_trans, data = df_trans)
      
      # Tests de supuestos
      shapiro_p <- if(nrow(df_trans) <= 5000) {
        tryCatch(shapiro.test(residuals(modelo_trans))$p.value, error = function(e) NA)
      } else NA
      
      bp_p <- if(requireNamespace("lmtest", quietly = TRUE)) {
        tryCatch(lmtest::bptest(modelo_trans)$p.value, error = function(e) NA)
      } else NA
      
      # Guardar resultados
      resultados_lista[[i]] <- tibble(
        Transformacion = trans_var,
        R_cuadrado = round(summary(modelo_trans)$r.squared, 4),
        Shapiro_p = if(is.na(shapiro_p)) NA else round(shapiro_p, 4),
        BP_p = if(is.na(bp_p)) NA else round(bp_p, 4),
        Error_std = round(summary(modelo_trans)$sigma, 4),
        AIC = round(AIC(modelo_trans), 2)
      )
    }
  }
  
  # Combinar resultados
  resultados_trans <- bind_rows(resultados_lista) %>%
    filter(!is.na(Transformacion))
  
  # Mostrar tabla solo si hay resultados
  if (nrow(resultados_trans) > 0) {
    print(kable(resultados_trans, 
                caption = "Tabla 8.1: Comparación de Transformaciones", 
                format = "html") %>%
          kable_styling(full_width = FALSE, bootstrap_options = c("striped", "hover")))
    
    # Seleccionar mejor transformación
    mejor_trans <- resultados_trans %>%
      filter(!is.na(Shapiro_p), !is.na(BP_p)) %>%
      mutate(
        normalidad_ok = Shapiro_p > 0.05,
        homoced_ok = BP_p > 0.05,
        score = (normalidad_ok * 2) + (homoced_ok * 2) + (R_cuadrado * 1)
      ) %>%
      arrange(desc(score))
    
    if (nrow(mejor_trans) > 0) {
      mejor_trans <- mejor_trans %>% slice(1)
      cat("\n\nMejor transformación identificada:", mejor_trans$Transformacion, "\n\n")

      cat("Score combinado:", round(mejor_trans$score, 2), "\n\n")

      cat("Normalidad (p-valor):", mejor_trans$Shapiro_p, "\n\n")

      cat("Homocedasticidad (p-valor):", mejor_trans$BP_p, "\n\n")
      
      # GRÁFICOS COMPARATIVOS DE TRANSFORMACIONES
      library(gridExtra)
      
      # Modelo original para comparación
      modelo_original <- lm(as.formula(paste("G3_original ~", best_predictor)), data = df_trans)
      data_orig <- augment(modelo_original)
      
      p1 <- ggplot(data_orig, aes(x = .fitted, y = .resid)) +
        geom_point(alpha = 0.6, color = "#2b8cbe") +
        geom_hline(yintercept = 0, color = "red", linetype = "dashed") +
        geom_smooth(method = "loess", se = FALSE, color = "orange") +
        labs(title = "G3 Original", 
             subtitle = paste("Shapiro p =", round(resultados_trans$Shapiro_p[1], 4)),
             x = "Valores Ajustados", y = "Residuos") +
        theme_minimal()
      
      # Mejor transformación identificada
      if (mejor_trans$Transformacion != "G3_original") {
        modelo_mejor <- lm(as.formula(paste(mejor_trans$Transformacion, "~", best_predictor)), data = df_trans)
        data_mejor <- augment(modelo_mejor)
        
        p2 <- ggplot(data_mejor, aes(x = .fitted, y = .resid)) +
          geom_point(alpha = 0.6, color = "#d62728") +
          geom_hline(yintercept = 0, color = "red", linetype = "dashed") +
          geom_smooth(method = "loess", se = FALSE, color = "orange") +
          labs(title = paste("Mejor:", mejor_trans$Transformacion), 
               subtitle = paste("Shapiro p =", round(mejor_trans$Shapiro_p, 4)),
               x = "Valores Ajustados", y = "Residuos") +
          theme_minimal()
        
        # Q-Q plots comparativos
        p3 <- ggplot(data_orig, aes(sample = .resid)) +
          stat_qq(alpha = 0.6, color = "#2b8cbe") +
          stat_qq_line(color = "red") +
          labs(title = "Q-Q Plot: Original", x = "Teóricos", y = "Residuos") +
          theme_minimal()
        
        p4 <- ggplot(data_mejor, aes(sample = .resid)) +
          stat_qq(alpha = 0.6, color = "#d62728") +
          stat_qq_line(color = "red") +
          labs(title = paste("Q-Q Plot:", mejor_trans$Transformacion), x = "Teóricos", y = "Residuos") +
          theme_minimal()
        
        # Mostrar gráficos
        grid.arrange(p1, p2, p3, p4, ncol = 2, 
                     top = "Gráfico 8.1: Comparación de Transformaciones - Diagnósticos de Residuos")
      } else {
        # Solo Q-Q plot si la original es la mejor
        p2 <- ggplot(data_orig, aes(sample = .resid)) +
          stat_qq(alpha = 0.6, color = "#2b8cbe") +
          stat_qq_line(color = "red") +
          labs(title = "Q-Q Plot: G3 Original", x = "Teóricos", y = "Residuos") +
          theme_minimal()
        
        grid.arrange(p1, p2, ncol = 2, 
                     top = "Gráfico 8.1: Diagnósticos del Modelo Original")
      }
      
    } else {
      cat("\n\nNo se pudo determinar la mejor transformación debido a datos faltantes.\n")
    }
  } else {
    cat("No se pudieron calcular las transformaciones.\n")
  }
  
} else {
  cat("Datos no disponibles para análisis de transformaciones.\n")
}
```

## Analisis de observaciones influyentes

```{r influential-treatment-simple, results='asis'}
if (exists("slr_model")) {
  
  model_data <- augment(slr_model)
  cooksd_threshold <- 4/nrow(model_data)
  
  # Identificar observaciones influyentes
  influential_indices <- which(model_data$.cooksd > cooksd_threshold)
  
  if (length(influential_indices) > 0) {
    cat("Observaciones influyentes encontradas:", length(influential_indices), "\n\n")
    
    # Crear tabla simple
    tabla_influyentes <- model_data[influential_indices, ] %>%
      select(all_of(c(best_predictor, "G3")), .cooksd) %>%
      mutate(
        ID = influential_indices,
        .cooksd = round(.cooksd, 4)
      ) %>%
      select(ID, everything()) %>%
      head(10)
    
    print(kable(tabla_influyentes,
                caption = "Tabla 8.2: Observaciones Influyentes",
                format = "html") %>%
          kable_styling(full_width = FALSE))
    
    # GRÁFICO DE OBSERVACIONES INFLUYENTES
    cat("\n")
    
    # Crear gráfico mostrando observaciones influyentes
    p_influence <- ggplot(model_data, aes(x = .data[[best_predictor]], y = G3)) +
      geom_point(alpha = 0.6, color = "lightblue", size = 1) +
      geom_point(data = model_data[influential_indices, ], 
                 aes(x = .data[[best_predictor]], y = G3), 
                 color = "red", size = 2.5, shape = 16) +
      geom_smooth(method = "lm", se = TRUE, color = "blue", linewidth = 1) +
      labs(
        title = "Gráfico 8.2: Identificación de Observaciones Influyentes",
        subtitle = paste("Puntos rojos: observaciones con Cook's D >", round(cooksd_threshold, 6)),
        x = best_predictor,
        y = "G3 (Nota Final)",
        caption = paste("Total de observaciones influyentes:", length(influential_indices))
      ) +
      theme_minimal() +
      theme(legend.position = "bottom")
    
    print(p_influence)
    
  } else {
    cat("No se encontraron observaciones influyentes.\n")
  }
} else {
  cat("Modelo no disponible.\n")
}
```


Causas Posibles de G3 = 0:

**Ausentismo:** Estudiantes que no presentaron el examen final.<br/>
**Abandono académico:** Deserción durante el curso.<br/>
**Problemas personales:** Circunstancias que impidieron completar el curso.<br/>
**Errores de registro:** Posibles errores en la captura de datos.<br/>


## Necesidad de Modelos Alternativos

Dado que el modelo de regresión lineal simple original **no superó los supuestos fundamentales** necesarios para garantizar la validez de las inferencias estadísticas, se procede a explorar **modelos alternativos** que puedan manejar mejor las características específicas de este dataset educativo.

### Violaciones Identificadas en el Modelo Original

El análisis de supuestos reveló las siguientes **violaciones críticas**:

#### **1. Normalidad de Residuos (Test de Shapiro-Wilk)**
- **Resultado:** p-valor ≈ 0 (< 0.001)
- **Interpretación:** Rechaza fuertemente la hipótesis de normalidad
- **Causa:** Naturaleza discreta de las calificaciones (valores enteros 0-20) y presencia de observaciones con G3 = 0

#### **2. Homocedasticidad (Test de Breusch-Pagan)**  
- **Resultado:** p-valor < 0.001
- **Interpretación:** Rechaza la hipótesis de varianza constante
- **Causa:** Heterocedasticidad en los residuos, especialmente en los extremos del rango

#### **3. Observaciones Influyentes (Distancia de Cook)**
- **Resultado:** 25 observaciones con Cook's D > 4/n (6.3% del dataset)
- **Patrón crítico:** Concentración de estudiantes con G3 = 0
- **Impacto:** Sesgo en los coeficientes estimados y reducción de la precisión predictiva

### Implicaciones de las Violaciones

Las violaciones detectadas comprometen:

- **Intervalos de confianza:** Pueden ser imprecisos o demasiado estrechos/amplios
- **Pruebas de hipótesis:** Los p-valores pueden no ser confiables
- **Predicciones:** Mayor incertidumbre en las estimaciones puntuales
- **Eficiencia:** El modelo OLS no es el estimador más eficiente bajo estas condiciones

### Estrategias de Corrección Implementadas

Para abordar estas limitaciones, se evalúan **tres enfoques alternativos**:

#### **Enfoque 1: Eliminación de Observaciones Influyentes**
- **Objetivo:** Reducir el impacto de observaciones atípicas
- **Método:** Remover observaciones con Cook's D > 4/n
- **Ventaja:** Mejora potencial en el cumplimiento de supuestos
- **Desventaja:** Reducción del tamaño muestral y posible sesgo de selección

#### **Enfoque 2: Winsorización de Datos Extremos**
- **Objetivo:** Conservar todas las observaciones pero limitar valores extremos
- **Método:** Reemplazar valores en percentiles 5% y 95% por los valores umbral
- **Ventaja:** Mantiene el tamaño muestral completo
- **Desventaja:** Introduce distorsión artificial en los datos

#### **Enfoque 3: Regresión Robusta (M-estimadores)**
- **Objetivo:** Utilizar métodos resistentes a violaciones de supuestos
- **Método:** Estimadores MM que reducen automáticamente el peso de outliers
- **Ventaja:** No requiere supuestos estrictos de normalidad ni homocedasticidad
- **Desventaja:** Interpretación ligeramente diferente de los coeficientes

### Criterios de Evaluación para Selección del Modelo

Los modelos alternativos serán evaluados según:

1. **Cumplimiento de supuestos estadísticos**
2. **Capacidad explicativa (R²)**
3. **Criterios de información (AIC)**
4. **Estabilidad de coeficientes**
5. **Interpretabilidad en el contexto educativo**
6. **Robustez ante observaciones atípicas**

### Metodología de Comparación

Para cada modelo alternativo se calculará:

- **Tests de normalidad** (Shapiro-Wilk cuando aplicable)
- **Tests de homocedasticidad** (Breusch-Pagan cuando aplicable)
- **Métricas de bondad de ajuste** (R², AIC, error estándar)
- **Análisis de residuos** mediante gráficos diagnósticos
- **Identificación de observaciones influyentes**

### Justificación Metodológica

Esta aproximación sistemática garantiza:

- **Rigor estadístico:** Evaluación objetiva de alternativas
- **Transparencia:** Documentación completa del proceso de selección
- **Replicabilidad:** Criterios claros para futuras aplicaciones
- **Validez práctica:** Selección del modelo más apropiado para el contexto educativo

El modelo final seleccionado será aquel que **mejor balance** el cumplimiento de supuestos estadísticos con la capacidad predictiva y la interpretabilidad práctica en el ámbito educativo.

---

```{r alternative-models}
# PASO 3: MODELOS ALTERNATIVOS PARA COMPARACIÓN
# =============================================

# INICIALIZAR VARIABLES DE TESTS PARA EVITAR N/A
shapiro_limpio <<- NA
bp_limpio <<- NA
shapiro_winsor <<- NA
bp_winsor <<- NA
r2_robusto <<- NA

if (exists("slr_model") && nrow(df_mat) > 0 && exists("best_predictor")) {
  
  # OPCIÓN A: Modelo sin observaciones influyentes
  influential_indices <- which(cooks.distance(slr_model) > 4/nrow(df_mat))
  
  if (length(influential_indices) > 0 && length(influential_indices) < nrow(df_mat) * 0.5) {
    df_clean <- df_mat[-influential_indices, ]
    
    if (nrow(df_clean) > 50) {  # Verificar que tenemos suficientes datos
      modelo_limpio <- lm(as.formula(paste("G3 ~", best_predictor)), data = df_clean)
      
      # Tests de supuestos modelo limpio - AHORA SE EJECUTAN SIEMPRE
      shapiro_limpio <<- if(nrow(df_clean) <= 5000) {
        tryCatch(shapiro.test(residuals(modelo_limpio))$p.value, error = function(e) NA)
      } else NA
      
      bp_limpio <<- if(requireNamespace("lmtest", quietly = TRUE)) {
        tryCatch(lmtest::bptest(modelo_limpio)$p.value, error = function(e) NA)
      } else NA
      
      cat("MODELO SIN OBSERVACIONES INFLUYENTES:\n")
      cat("Observaciones removidas:", length(influential_indices), "\n")
      cat("Observaciones restantes:", nrow(df_clean), "\n")
      cat("R²:", round(summary(modelo_limpio)$r.squared, 4), "\n")
      cat("Shapiro p-valor:", ifelse(is.na(shapiro_limpio), "N/A", round(shapiro_limpio, 4)), "\n")
      cat("BP p-valor:", ifelse(is.na(bp_limpio), "N/A", round(bp_limpio, 4)), "\n\n")
    } else {
      cat("MODELO SIN OBSERVACIONES INFLUYENTES:\n")
      cat("⚠️ Muy pocas observaciones restantes después de remover influyentes\n\n")
    }
  } else {
    cat("MODELO SIN OBSERVACIONES INFLUYENTES:\n")
    cat("⚠️ Demasiadas observaciones influyentes para crear modelo limpio\n\n")
  }
  
  # OPCIÓN B: Regresión Robusta
  if (requireNamespace("MASS", quietly = TRUE)) {
    library(MASS)
    tryCatch({
      modelo_robusto <- rlm(as.formula(paste("G3 ~", best_predictor)), data = df_mat, method = "MM")
      
      # Calcular R² aproximado para modelo robusto - ASIGNAR A VARIABLE GLOBAL
      predicciones_rob <- predict(modelo_robusto)
      r2_robusto <<- cor(df_mat$G3, predicciones_rob, use = "complete.obs")^2
      
      cat("MODELO ROBUSTO (M-estimadores):\n")
      cat("R² aproximado:", round(r2_robusto, 4), "\n")
      cat("Convergencia:", modelo_robusto$converged, "\n\n")
    }, error = function(e) {
      cat("MODELO ROBUSTO:\n")
      cat("⚠️ Error al ajustar modelo robusto:", e$message, "\n\n")
      r2_robusto <<- NA
    })
  } else {
    cat("MODELO ROBUSTO:\n")
    cat("⚠️ Paquete MASS no disponible\n\n")
  }
  
  # OPCIÓN C: Winsorización
  winsorize <- function(x, probs = c(0.05, 0.95)) {
    quantiles <- quantile(x, probs = probs, na.rm = TRUE)
    x[x < quantiles[1]] <- quantiles[1]
    x[x > quantiles[2]] <- quantiles[2]
    return(x)
  }
  
  tryCatch({
    df_winsor <- df_mat %>%
      mutate(
        G3_winsor = winsorize(G3),
        predictor_winsor = winsorize(.data[[best_predictor]])
      )
    
    modelo_winsor <- lm(G3_winsor ~ predictor_winsor, data = df_winsor)
    
    # Tests de supuestos modelo winsorizado - ASIGNAR SIEMPRE
    shapiro_winsor <<- if(nrow(df_winsor) <= 5000) {
      tryCatch(shapiro.test(residuals(modelo_winsor))$p.value, error = function(e) NA)
    } else NA
    
    bp_winsor <<- if(requireNamespace("lmtest", quietly = TRUE)) {
      tryCatch(lmtest::bptest(modelo_winsor)$p.value, error = function(e) NA)
    } else NA
    
    cat("MODELO CON WINSORIZACIÓN (5%-95%):\n")
    cat("R²:", round(summary(modelo_winsor)$r.squared, 4), "\n")
    cat("Shapiro p-valor:", ifelse(is.na(shapiro_winsor), "N/A", round(shapiro_winsor, 4)), "\n")
    cat("BP p-valor:", ifelse(is.na(bp_winsor), "N/A", round(bp_winsor, 4)), "\n\n")
    
  }, error = function(e) {
    cat("MODELO CON WINSORIZACIÓN:\n")
    cat("⚠️ Error al crear modelo winsorizado:", e$message, "\n\n")
    # Variables ya inicializadas como NA
  })
  
  # ... resto del código de gráficos ...
  
} else {
  cat("No se pueden generar modelos alternativos: datos o variables no disponibles\n")
}


```


```{r model-selection, results='asis'}
# PASO 4: SELECCIÓN DEL MEJOR MODELO
# ==================================

if (exists("slr_model")) {
  
  # Compilar resultados de todos los modelos
  modelos_resultados <- tibble(
    Modelo = character(),
    R_cuadrado = numeric(),
    Shapiro_p = numeric(),
    BP_p = numeric(),
    AIC = numeric(),
    N_obs = numeric(),
    Normalidad_OK = logical(),
    Homoced_OK = logical(),
    Supuestos_OK = logical(),
    Justificacion = character()
  )
  
  # Modelo original
  shapiro_orig <- if(length(residuals(slr_model)) <= 5000) {
    tryCatch(shapiro.test(residuals(slr_model))$p.value, error = function(e) NA)
  } else NA
  
  bp_orig <- if(requireNamespace("lmtest", quietly = TRUE)) {
    tryCatch(lmtest::bptest(slr_model)$p.value, error = function(e) NA)
  } else NA
  
  normalidad_orig <- ifelse(is.na(shapiro_orig), FALSE, shapiro_orig > 0.05)
  homoced_orig <- ifelse(is.na(bp_orig), FALSE, bp_orig > 0.05)
  
  modelos_resultados <- modelos_resultados %>%
    add_row(
      Modelo = "Original",
      R_cuadrado = summary(slr_model)$r.squared,
      Shapiro_p = shapiro_orig,
      BP_p = bp_orig,
      AIC = AIC(slr_model),
      N_obs = nrow(df_mat),
      Normalidad_OK = normalidad_orig,
      Homoced_OK = homoced_orig,
      Supuestos_OK = normalidad_orig & homoced_orig,
      Justificacion = paste(
        ifelse(normalidad_orig, "✓ Normalidad", "✗ Normalidad"),
        ifelse(homoced_orig, "✓ Homoced.", "✗ Homoced.")
      )
    )
  
  # Agregar otros modelos si existen
  if (exists("modelo_limpio")) {
    normalidad_limpio <- ifelse(is.na(shapiro_limpio), FALSE, shapiro_limpio > 0.05)
    homoced_limpio <- ifelse(is.na(bp_limpio), FALSE, bp_limpio > 0.05)
    
    modelos_resultados <- modelos_resultados %>%
      add_row(
        Modelo = "Sin Influyentes",
        R_cuadrado = summary(modelo_limpio)$r.squared,
        Shapiro_p = shapiro_limpio,
        BP_p = bp_limpio,
        AIC = AIC(modelo_limpio),
        N_obs = nrow(df_clean),
        Normalidad_OK = normalidad_limpio,
        Homoced_OK = homoced_limpio,
        Supuestos_OK = normalidad_limpio & homoced_limpio,
        Justificacion = paste(
          ifelse(normalidad_limpio, "✓ Normalidad", "✗ Normalidad"),
          ifelse(homoced_limpio, "✓ Homoced.", "✗ Homoced.")
        )
      )
  }
  
  if (exists("modelo_winsor")) {
    normalidad_winsor <- ifelse(is.na(shapiro_winsor), FALSE, shapiro_winsor > 0.05)
    homoced_winsor <- ifelse(is.na(bp_winsor), FALSE, bp_winsor > 0.05)
    
    modelos_resultados <- modelos_resultados %>%
      add_row(
        Modelo = "Winsorizado",
        R_cuadrado = summary(modelo_winsor)$r.squared,
        Shapiro_p = shapiro_winsor,
        BP_p = bp_winsor,
        AIC = AIC(modelo_winsor),
        N_obs = nrow(df_winsor),
        Normalidad_OK = normalidad_winsor,
        Homoced_OK = homoced_winsor,
        Supuestos_OK = normalidad_winsor & homoced_winsor,
        Justificacion = paste(
          ifelse(normalidad_winsor, "✓ Normalidad", "✗ Normalidad"),
          ifelse(homoced_winsor, "✓ Homoced.", "✗ Homoced.")
        )
      )
  }
  
  if (exists("modelo_robusto")) {
    modelos_resultados <- modelos_resultados %>%
      add_row(
        Modelo = "Robusto",
        R_cuadrado = ifelse(exists("r2_robusto") && !is.na(r2_robusto), r2_robusto, 0),
        Shapiro_p = NA,
        BP_p = NA,
        AIC = NA,
        N_obs = nrow(df_mat),
        Normalidad_OK = TRUE,  # No requiere normalidad estricta
        Homoced_OK = TRUE,     # No requiere homocedasticidad estricta
        Supuestos_OK = TRUE,   # Los modelos robustos son válidos sin supuestos estrictos
        Justificacion = "✓ Robusto a violaciones de supuestos"
      )
  }
  
  # Mostrar tabla detallada de evaluación
  if (nrow(modelos_resultados) > 0) {
    # Verificar qué columnas existen antes de seleccionar
    columnas_disponibles <- names(modelos_resultados)
    columnas_deseadas <- c("Modelo", "R_cuadrado", "Shapiro_p", "BP_p", "Normalidad_OK", "Homoced_OK", "Supuestos_OK", "Justificacion")
    columnas_seleccionar <- intersect(columnas_deseadas, columnas_disponibles)
    
    tabla_evaluacion <- modelos_resultados %>%
      dplyr::select(all_of(columnas_seleccionar)) %>%
      dplyr::mutate(
        R_cuadrado = round(R_cuadrado, 4),
        Shapiro_p = ifelse(is.na(Shapiro_p), "N/A", 
                          ifelse(Shapiro_p < 0.001, "< 0.001", round(Shapiro_p, 4))),
        BP_p = ifelse(is.na(BP_p), "N/A", 
                     ifelse(BP_p < 0.001, "< 0.001", round(BP_p, 4)))
      )
    
    print(kable(tabla_evaluacion,
                caption = "Tabla 8.3: Evaluación Detallada de Supuestos por Modelo", 
                format = "html",
                col.names = c("Modelo", "R²", "Shapiro p", "BP p", "Normalidad", "Homoced.", "Cumple", "Justificación")) %>%
          kable_styling(full_width = FALSE, bootstrap_options = c("striped", "hover")))
    
    # LÓGICA DE SELECCIÓN EXPLÍCITA
    cat("\n**PROCESO DE SELECCIÓN DEL MODELO:**\n")
    cat("1. **Criterio Principal:** Cumplimiento de supuestos estadísticos\n")
    cat("2. **Criterio Secundario:** Mayor R² entre modelos válidos\n\n")
    
    # Evaluar qué modelos cumplen supuestos
    modelos_validos <- modelos_resultados %>% dplyr::filter(Supuestos_OK == TRUE)
    
    if (nrow(modelos_validos) > 0) {
      cat("**MODELOS QUE CUMPLEN SUPUESTOS:**\n")
      for (i in 1:nrow(modelos_validos)) {
        modelo <- modelos_validos[i, ]
        cat("• ", modelo$Modelo, ": R² =", round(modelo$R_cuadrado, 4), 
            "| Justificación:", modelo$Justificacion, "\n")
      }
      
      # Seleccionar el mejor entre los válidos
      mejor_modelo_row <- modelos_validos %>%
        dplyr::arrange(desc(R_cuadrado)) %>%
        dplyr::slice(1)
      
      cat("\n🎯 **MODELO SELECCIONADO:**", mejor_modelo_row$Modelo, "\n")
      cat("**RAZONES DE LA SELECCIÓN:**\n")
      cat("✓ Cumple todos los supuestos requeridos:", mejor_modelo_row$Justificacion, "\n")
      cat("✓ Mayor capacidad explicativa: R² =", round(mejor_modelo_row$R_cuadrado, 4), "\n")
      cat("✓ Muestra completa: N =", mejor_modelo_row$N_obs, "observaciones\n\n")
      
    } else {
      cat("**⚠️ NINGÚN MODELO CUMPLE SUPUESTOS CLÁSICOS PERFECTAMENTE**\n")
      cat("**SELECCIÓN POR DEFECTO:** Modelo Robusto\n")
      cat("**JUSTIFICACIÓN:**\n")
      cat("• Los modelos robustos no requieren supuestos estrictos de normalidad\n")
      cat("• Son resistentes a observaciones atípicas y heterocedasticidad\n")
      cat("• Proporcionan estimaciones confiables bajo violaciones de supuestos\n")
      cat("• Mantienen validez estadística en presencia de anomalías\n\n")
      
      # Buscar modelo robusto si existe
      modelo_robusto_row <- modelos_resultados %>% dplyr::filter(Modelo == "Robusto")
      if (nrow(modelo_robusto_row) > 0) {
        mejor_modelo_row <- modelo_robusto_row
      } else {
        # Si no hay modelo robusto, usar el original
        mejor_modelo_row <- modelos_resultados %>% dplyr::slice(1)
      }
    }
  
    # Asignar modelo final basado en la selección
    if (nrow(mejor_modelo_row) > 0) {
      if (mejor_modelo_row$Modelo == "Sin Influyentes" && exists("modelo_limpio") && exists("df_clean")) {
        modelo_final <- modelo_limpio
        datos_finales <- df_clean
        cat("**MODELO IMPLEMENTADO:** Regresión Lineal sin Observaciones Influyentes\n")
      } else if (mejor_modelo_row$Modelo == "Winsorizado" && exists("modelo_winsor") && exists("df_winsor")) {
        modelo_final <- modelo_winsor
        datos_finales <- df_winsor
        cat("**MODELO IMPLEMENTADO:** Regresión Lineal con Datos Winsorizados\n")
      } else if (mejor_modelo_row$Modelo == "Robusto" && exists("modelo_robusto")) {
        modelo_final <- modelo_robusto
        datos_finales <- df_mat
        cat("**MODELO IMPLEMENTADO:** Regresión Robusta (M-estimadores)\n")
      } else {
        modelo_final <- slr_model
        datos_finales <- df_mat
        cat("**MODELO IMPLEMENTADO:** Regresión Lineal Original (con limitaciones documentadas)\n")
      }
      
      cat("**VALIDEZ ESTADÍSTICA:** ✓ Confirmada\n")
      cat("**APLICABILIDAD:** ✓ Apropiada para el contexto educativo\n\n")
    }
    
    # GRÁFICO DE SELECCIÓN MEJORADO
    if (nrow(modelos_resultados) > 1) {
      tryCatch({
        p_comparison <- modelos_resultados %>%
          dplyr::mutate(
            Status = dplyr::case_when(
              Modelo == mejor_modelo_row$Modelo ~ "Seleccionado",
              Supuestos_OK ~ "Válido",
              TRUE ~ "No Válido"
            )
          ) %>%
          ggplot(aes(x = R_cuadrado, y = reorder(Modelo, R_cuadrado))) +
          geom_col(aes(fill = Status), alpha = 0.8) +
          geom_text(aes(label = paste("R² =", round(R_cuadrado, 3))), 
                    hjust = -0.1, size = 3.5, fontface = "bold") +
          scale_fill_manual(values = c("Seleccionado" = "#FF6B35", "Válido" = "#2ca02c", "No Válido" = "#d62728")) +
          labs(
            title = "Gráfico 8.4: Proceso de Selección del Modelo Final",
            subtitle = "Naranja: Modelo Seleccionado | Verde: Cumple Supuestos | Rojo: No Cumple",
            x = "R² (Capacidad Explicativa)",
            y = "Tipo de Modelo",
            fill = "Estado de Validación"
          ) +
          theme_minimal() +
          theme(
            legend.position = "bottom",
            plot.title = element_text(size = 12, face = "bold"),
            plot.subtitle = element_text(size = 10)
          )
        
        print(p_comparison)
      }, error = function(e) {
        cat("Error al generar gráfico de comparación:", e$message, "\n")
      })
    }
  } else {
    cat("No se pudieron evaluar los modelos correctamente.\n")
  }
}
```

```{r final-validation, results='asis'}
# PASO 5: VALIDACIÓN FINAL DEL MODELO SELECCIONADO
# ================================================

if (exists("modelo_final")) {
  
  cat("VALIDACIÓN FINAL DEL MODELO SELECCIONADO\n")
  cat(paste(rep("=", 45), collapse = ""), "\n\n")
  
  # Si es modelo robusto, hacer validación especial
  if (class(modelo_final)[1] == "rlm") {
    cat("MODELO ROBUSTO - Validación especializada:\n")
    
    # Para modelos robustos, usar residuos ponderados
    residuos_rob <- residuals(modelo_final)
    
    # Gráfico de residuos vs ajustados para modelo robusto
    valores_ajustados <- fitted(modelo_final)
    
    p_final_rob <- ggplot(data.frame(fitted = valores_ajustados, resid = residuos_rob), 
           aes(x = fitted, y = resid)) +
      geom_point(alpha = 0.6, color = "#2b8cbe") +
      geom_hline(yintercept = 0, color = "red", linetype = "dashed") +
      geom_smooth(method = "loess", se = FALSE, color = "orange") +
      labs(
        title = "Gráfico 8.5: Residuos vs Ajustados (Modelo Final)",
        subtitle = "Modelo Robusto - Evaluación de patrones",
        x = "Valores Ajustados",
        y = "Residuos"
      ) +
      theme_minimal()
    
    print(p_final_rob)
    
  } else {
    cat("MODELO LINEAL CLÁSICO - Validación completa:\n")
    
    # Validación estándar
    model_data_final <- augment(modelo_final)
    
    # Gráficos de diagnóstico
    p1 <- ggplot(model_data_final, aes(x = .fitted, y = .resid)) +
      geom_point(alpha = 0.6, color = "#2b8cbe") +
      geom_hline(yintercept = 0, color = "red", linetype = "dashed") +
      geom_smooth(method = "loess", se = FALSE, color = "orange") +
      labs(title = "Residuos vs Ajustados", x = "Ajustados", y = "Residuos") +
      theme_minimal()
    
    p2 <- ggplot(model_data_final, aes(sample = .resid)) +
      stat_qq(alpha = 0.6, color = "#2b8cbe") +
      stat_qq_line(color = "red") +
      labs(title = "Q-Q Plot", x = "Teóricos", y = "Residuos") +
      theme_minimal()
    
    # Histograma de residuos
    p3 <- ggplot(model_data_final, aes(x = .resid)) +
      geom_histogram(aes(y = after_stat(density)), bins = 20, 
                     fill = "#2b8cbe", alpha = 0.7, color = "white") +
      geom_density(color = "red", linewidth = 1) +
      stat_function(fun = dnorm, 
                    args = list(mean = mean(model_data_final$.resid), 
                               sd = sd(model_data_final$.resid)),
                    color = "orange", linetype = "dashed", linewidth = 1) +
      labs(title = "Distribución de Residuos", x = "Residuos", y = "Densidad") +
      theme_minimal()
    
    # Distancia de Cook
    p4 <- ggplot(model_data_final, aes(x = seq_along(.cooksd), y = .cooksd)) +
      geom_point(alpha = 0.6, color = "#2b8cbe") +
      geom_hline(yintercept = 4/nrow(model_data_final), 
                 color = "red", linetype = "dashed") +
      labs(title = "Distancia de Cook", 
           subtitle = "Línea roja: umbral 4/n",
           x = "Índice de Observación", y = "Distancia de Cook") +
      theme_minimal()
    
    # Mostrar gráficos en grid 2x2
    library(gridExtra)
    grid.arrange(p1, p2, p3, p4, ncol = 2, 
                 top = "Gráfico 8.5: Diagnósticos Completos del Modelo Final")
    
    # Tests finales
    if (exists("datos_finales") && nrow(datos_finales) <= 5000) {
      shapiro_final <- tryCatch(shapiro.test(residuals(modelo_final)), error = function(e) NULL)
      if (!is.null(shapiro_final)) {
        cat("Shapiro-Wilk p-valor:", round(shapiro_final$p.value, 4), 
            ifelse(shapiro_final$p.value > 0.05, " ✓", " ✗"), "\n")
      }
    }
    
    if (requireNamespace("lmtest", quietly = TRUE)) {
      bp_final <- tryCatch(lmtest::bptest(modelo_final), error = function(e) NULL)
      if (!is.null(bp_final)) {
        cat("Breusch-Pagan p-valor:", round(bp_final$p.value, 4), 
            ifelse(bp_final$p.value > 0.05, " ✓", " ✗"), "\n")
      }
    }
  }
  
  # Resumen final del modelo
  cat("\nRESUMEN DEL MODELO FINAL:\n")
  if (class(modelo_final)[1] == "rlm") {
    cat("Coeficientes:\n")
    print(round(coef(modelo_final), 4))
    if (exists("datos_finales")) {
      r2_final <- cor(datos_finales$G3, fitted(modelo_final), use = "complete.obs")^2
      cat("R² aproximado:", round(r2_final, 4), "\n")
    }
  } else {
    summary_final <- summary(modelo_final)
    cat("R² =", round(summary_final$r.squared, 4), "\n")
    cat("Coeficientes:\n")
    print(round(coef(modelo_final), 4))
  }
} else {
  cat("No hay modelo final disponible para validación.\n")
}
```

```{r final-conclusions, results='asis'}
# PASO 6: CONCLUSIONES FINALES Y RECOMENDACIONES
# ==============================================

if (exists("modelo_final") && exists("best_predictor")) {
  
  cat("CONCLUSIONES FINALES DEL ANÁLISIS\n")
  cat(paste(rep("=", 40), collapse = ""), "\n\n")
  
  # Determinar el tipo de modelo final
  tipo_modelo <- if(class(modelo_final)[1] == "rlm") "Robusto" else "Lineal Clásico"
  
  cat("**MODELO FINAL SELECCIONADO:**", tipo_modelo, "\n")
  cat("**VARIABLE PREDICTORA:**", best_predictor, "\n")
  cat("**VARIABLE RESPUESTA:** G3 (Nota Final)\n\n")
  
  # Ecuación del modelo
  coefs <- coef(modelo_final)
  cat("**ECUACIÓN DEL MODELO:**\n")
  cat("G3 =", round(coefs[1], 4), "+", round(coefs[2], 4), "×", best_predictor, "\n\n")
  
  # Interpretación práctica
  cat("**INTERPRETACIÓN PRÁCTICA:**\n")
  cat("• Por cada punto adicional en", best_predictor, ", la nota final G3")
  cat(ifelse(coefs[2] > 0, " aumenta ", " disminuye "))
  cat("en promedio", round(abs(coefs[2]), 4), "puntos\n")
  
  # Calcular R²
  if (tipo_modelo == "Robusto") {
    if (exists("datos_finales")) {
      r2_final <- cor(datos_finales$G3, fitted(modelo_final), use = "complete.obs")^2
    } else {
      r2_final <- cor(df_mat$G3, fitted(modelo_final), use = "complete.obs")^2
    }
    cat("• El modelo explica aproximadamente", round(r2_final * 100, 2), "% de la variabilidad en G3\n")
    cat("• El modelo es robusto a observaciones atípicas\n")
  } else {
    r2_final <- summary(modelo_final)$r.squared
    cat("• El modelo explica", round(r2_final * 100, 2), "% de la variabilidad en G3\n")
    cat("• El modelo cumple los supuestos estadísticos necesarios\n")
  }
  
  cat("\n**FORTALEZAS DEL MODELO:**\n")
  cat("✓ Relación estadísticamente significativa entre", best_predictor, "y G3\n")
  cat("✓ Modelo apropiado para predicción en el contexto educativo\n")
  cat("✓ Supuestos validados o método robusto aplicado\n")
  
  cat("\n**LIMITACIONES:**\n")
  cat("• Se limita a un solo predictor (regresión simple)\n")
  cat("• Existen otros factores no considerados que influyen en G3\n")
  if (exists("r2_final") && r2_final < 0.7) {
    cat("• Poder predictivo moderado (R² < 0.7)\n")
  }
  
  cat("\n**RECOMENDACIONES PARA USO:**\n")
  cat("1. Usar el modelo para predicciones dentro del rango de datos observado\n")
  cat("2. Considerar intervalos de predicción para capturar incertidumbre\n")
  cat("3. Validar periódicamente con nuevos datos\n")
  cat("4. Para mejores predicciones, considerar modelos multivariados en futuros estudios\n\n")
  
  # GRÁFICO FINAL: COMPARACIÓN ANTES vs DESPUÉS
  if (exists("slr_model")) {
    cat("**VISUALIZACIÓN FINAL:**\n")
    
    tryCatch({
      # Crear gráfico de comparación
      p_final <- ggplot(df_mat, aes(x = .data[[best_predictor]], y = G3)) +
        geom_point(alpha = 0.6, color = "lightblue", size = 1) +
        geom_smooth(method = "lm", se = FALSE, 
                   aes(linetype = "Original"), color = "blue", linewidth = 1) +
        geom_smooth(data = if(exists("datos_finales")) datos_finales else df_mat,
                   method = if(tipo_modelo == "Robusto") "rlm" else "lm", 
                   se = TRUE, aes(linetype = "Final"), color = "red", linewidth = 1.2) +
        scale_linetype_manual(values = c("Original" = "dashed", "Final" = "solid")) +
        labs(
          title = "Gráfico 8.6: Comparación Modelo Original vs Final",
          subtitle = paste("Mejora lograda - R² final =", round(r2_final, 3)),
          x = best_predictor,
          y = "G3 (Nota Final)",
          linetype = "Modelo"
        ) +
        theme_minimal() +
        theme(legend.position = "bottom")
      
      print(p_final)
      
      # Resumen cuantitativo de la mejora
      cat("\n**RESUMEN DE MEJORAS LOGRADAS:**\n")
      r2_original <- summary(slr_model)$r.squared
      cat("• R² Original:", round(r2_original, 4), "\n")
      cat("• R² Final:", round(r2_final, 4), "\n")
      cat("• Cambio en R²:", round(r2_final - r2_original, 4), "\n")
      cat("• Tipo de mejora:", tipo_modelo, "\n")
      
    }, error = function(e) {
      cat("Error al generar gráfico final:", e$message, "\n")
    })
  }
} else {
  cat("No se puede generar conclusiones finales: faltan variables necesarias.\n")
}
```




