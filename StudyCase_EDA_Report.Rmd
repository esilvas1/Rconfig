---
title: "Análisis Exploratorio de Datos y Aplicación de Regresion Lineal Simple"
author: "Edwin Silva Salas - Actividad 3 - Metodos y Simulación Estadisticas"
date: "`r Sys.Date()`"
output:
  html_document:
    toc: true
    toc_depth: 2
    code_folding: hide
    number_sections: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, message = FALSE, warning = FALSE, fig.width = 8, fig.height = 5)
library(tidyverse)
library(knitr)
library(kableExtra)

# helper to safely read CSVs produced by EDA
safe_read <- function(path) {
  if (file.exists(path)) readr::read_csv(path) else tibble()
}

image_exists <- function(path) {
  file.exists(path)
}

# Cargar los datos originales para graficar en vivo
df_mat <- if (file.exists("student-mat.csv")) readr::read_csv2("student-mat.csv") else tibble()
df_por <- if (file.exists("student-por.csv")) readr::read_csv2("student-por.csv") else tibble()
```

# Resumen ejecutivo

Este informe contiene un análisis exploratorio de datos (EDA) para los conjuntos `student_mat.csv` y `student_por.csv`.Descargados de la url **https://archive.ics.uci.edu/dataset/320/student+performance**, Este informe incluye tablas descriptivas, identificación de valores faltantes, detección de outliers por la regla IQR, matrices y mapas de correlación, y gráficos de dispersión de la calificación o nota final de cada estudiante (G3) frente a las variables con mayor correlación.


# Aplicación: Análisis Exploratorio de Datos (EDA)
Se descarga de la ubicacion URL mencionda anteriormente un archivo (*.zip) con el contenido de los datos en archivos (*.csv) como insumo de esta actividad, se realiza su respectivo analisis EDA y posterior aplicacion del Modelo de Regresion Lineal Simple, **Simple Lineal Regression Model (SLRM)**

```{r files-check}
# confirmamos que los archivos base existen en el proyecto
cat("student-mat.csv:", file.exists("student-mat.csv"), "\n")
cat("student-por.csv:", file.exists("student-por.csv"), "\n")
```

Se muestran los nombres de las columnas o variables de los datasets **student_xxx** y se describe en español su significado o descripcion de columna en la **Tabla A9**:

```{r codebook_table, echo=FALSE, message=FALSE, warning=FALSE}
library(dplyr); library(tidyr); library(knitr); library(kableExtra)

# Reconstruir codebook_tbl si no existe (fallback rápido)
if (!exists("codebook_tbl")) {
  spanish_dict <- c(
    school="Escuela (GP/MS)", sex="Sexo (F/M)", age="Edad (años)", address="Dirección (U/R)",
    famsize="Tamaño familia (LE3/GT3)", Pstatus="Estado padres (T/A)", Medu="Educación madre (0-4)",
    Fedu="Educación padre (0-4)", Mjob="Trabajo madre", Fjob="Trabajo padre", reason="Razón",
    guardian="Tutor", traveltime="Tiempo viaje (1-4)", studytime="Tiempo estudio (1-4)",
    failures="Reprobadas previas", schoolsup="Apoyo escolar", famsup="Apoyo familiar",
    paid="Clases pagadas", activities="Actividades extra", nursery="Guardería", higher="Deseo superior",
    internet="Internet en casa", romantic="Relación romántica", famrel="Relación familiar (1-5)",
    freetime="Tiempo libre (1-5)", goout="Salir con amigos (1-5)", Dalc="Alcohol entre semana (1-5)",
    Walc="Alcohol fin de semana (1-5)", health="Salud (1-5)", absences="Ausencias", G1="Nota periodo 1",
    G2="Nota periodo 2", G3="Nota final (objetivo)"
  )
  all_cols <- unique(c(names(df_mat), names(df_por)))
  codebook_tbl <- tibble(variable = all_cols) %>%
    mutate(descripcion = spanish_dict[variable]) %>%
    mutate(descripcion = ifelse(is.na(descripcion), NA_character_, descripcion))
}

# Mostrar en 4 columnas (variable/descripcion como pares)
n <- nrow(codebook_tbl)
if (n > 0) {
  rows_per_col <- ceiling(n / 4)
  # dividir en 4 bloques por orden
  idx <- rep(1:4, each = rows_per_col)[1:n]
  blocks <- split(codebook_tbl, idx)
  pad_block <- function(df) {
    if (nrow(df) < rows_per_col) {
      bind_rows(df, tibble(variable = rep(NA_character_, rows_per_col - nrow(df)),
                           descripcion = rep(NA_character_, rows_per_col - nrow(df))))
    } else df
  }
  blocks <- lapply(blocks, pad_block)
  wide <- bind_cols(
    blocks[[1]] %>% rename(variable1 = variable, desc1 = descripcion),
    blocks[[2]] %>% rename(variable2 = variable, desc2 = descripcion),
    blocks[[3]] %>% rename(variable3 = variable, desc3 = descripcion),
    blocks[[4]] %>% rename(variable4 = variable, desc4 = descripcion)
  ) %>% mutate_all(~replace_na(as.character(.), ""))
  knitr::kable(wide, caption = "Tabla A9: Diccionario de columnas (4 columnas)", booktabs = TRUE) %>%
    kable_styling(full_width = FALSE)
} else {
  cat("No hay columnas para mostrar.\n")
}
```


## Resumen numérico: missing, Outlier and Correlation (student_mat)
A continuació se genera un resumen numerico del dataset **student_mat** reflejando estadisticamente valores que visualizan si es necesario imputar datos o limpiar registros en cuento a valores atipico o faltantes:

```{r mat-numeric}
# Crear resumen numérico directamente a partir de student-mat.csv
if (nrow(df_mat) > 0) {
  num_sum_mat <- df_mat %>%
    select(where(is.numeric)) %>%
    summarise(across(everything(), list(
      mean = ~mean(.x, na.rm = TRUE),
      sd = ~sd(.x, na.rm = TRUE),
      median = ~median(.x, na.rm = TRUE),
      min = ~min(.x, na.rm = TRUE),
      max = ~max(.x, na.rm = TRUE),
      missing = ~sum(is.na(.x))
    ), .names = "{.col}_{.fn}"))

  # Convertir a formato largo para mostrar
  num_sum_mat_long <- num_sum_mat %>%
    pivot_longer(everything(), names_to = "metric", values_to = "value") %>%
    separate(metric, into = c("variable","stat"), sep = "_(?=[^_]+$)") %>%
    pivot_wider(names_from = stat, values_from = value) %>%
    arrange(variable)

  num_sum_mat_long %>%
    kable(digits = 3, caption = "Tabla A5: Resumen numerico student_mat") %>%
    kable_styling(full_width = FALSE)
} else cat("Archivo student-mat.csv no encontrado o vacío.\n")
```

En el siguiente espacio se desea revisar toda la data **student_mat** con el fin de determinar si existen valores faltantes y asi iniciar un procedimiento de imputación de datos:

```{r mat-missing}
# Tabla de valores faltantes por variable (student_mat) — mostrar solo variables con missing > 0
if (nrow(df_mat) > 0) {
  missing_mat <- df_mat %>%
    summarise(across(everything(), ~sum(is.na(.)))) %>%
    pivot_longer(everything(), names_to = "variable", values_to = "missing") %>%
    arrange(desc(missing))

  missing_mat_filtered <- missing_mat %>% filter(missing > 0)

  if (nrow(missing_mat_filtered) > 0) {
    missing_mat_filtered %>%
      kable(digits = 0, caption = "Missing values — student_mat (solo variables con missing)") %>%
      kable_styling(full_width = FALSE)
  } else {
    cat("No se detectaron valores faltantes en student_mat.\n")
  }
} else cat("Archivo student-mat.csv no encontrado o vacío.\n")
```
Y como se puede visualizar el codigo arroja que la data no contiene valores faltantes, por lo que continuaremos con la sigueinte sesion.

### Boxplots y Correlación

A continuacion se grafican las variables numericas graficos **Boxplots** para visualizar las diferentes variables que presentan alguna posible variacion atipica en su conjunto de valores, como se pueden ver en las variables: traveltime, studytime, G2, freetime, Fedu, famrel, failures, Dalc, age, y absences en la grafica A1:


```{r mat_plots}
if (nrow(df_mat)>0) {
  library(ggplot2)
  # Boxplots por variables numéricas
  nums <- df_mat %>% select(where(is.numeric))
  if (ncol(nums) > 0) {
    nums_long <- nums %>% pivot_longer(everything(), names_to = "variable", values_to = "value")
    p2 <- ggplot(nums_long, aes(x = variable, y = value)) +
      geom_boxplot(outlier.size = 1, fill = "#74a9cf") +
      coord_flip() +
      labs(title = "Grafica A1: Boxplots variables numéricas (student_mat)") +
      theme_minimal()
    print(p2)
  }
} else {
  cat("Archivo student-mat.csv no encontrado o vacío.\n")
}
```

Aplicando la funcionalidad de detección de **Outliers** visualizamos en la sigueinte tabla (Tabla A4) la cantidad de valores que no se ajustan al rango o regla **IQR**.

```{r mat-outliers}
# Detección de outliers por regla IQR para variables numéricas
if (nrow(df_mat) > 0) {
  nums <- df_mat %>% select(where(is.numeric))
  out_mat <- map_dfr(names(nums), function(var) {
    x <- nums[[var]]
    if (all(is.na(x))) return(tibble(variable = var, outlier_count = 0))
    q1 <- quantile(x, 0.25, na.rm = TRUE)
    q3 <- quantile(x, 0.75, na.rm = TRUE)
    iqr <- q3 - q1
    lower <- q1 - 1.5 * iqr
    upper <- q3 + 1.5 * iqr
    tibble(variable = var, outlier_count = sum(x < lower | x > upper, na.rm = TRUE))
  })

  out_mat %>% filter(outlier_count > 0) %>%
    kable(digits = 0, caption = "Tabla A4: Outliers detectados (IQR) — student_mat") %>%
    kable_styling(full_width = FALSE)
} else cat("Archivo student-mat.csv no encontrado o vacío.\n")
```

En el siguiente grafico (Grafica A2) se realiza un grafico de correlación con las variables numericas con el fin de encontrar la posible relacion que puede existir en algunas variables tales como G1, G2, G3, Walc, Dalc, Fedu y Medu.

```{r mat_correlacion}
if (nrow(df_mat)>0) {
  library(ggplot2)
  # Mapa de correlación (numéricas)
  nums <- df_mat %>% select(where(is.numeric))
  if (ncol(nums) >= 2) {
    cor_mat <- cor(nums, use = "pairwise.complete.obs")
    cor_df <- as.data.frame(as.table(cor_mat))
    p3 <- ggplot(cor_df, aes(Var1, Var2, fill = Freq)) +
      geom_tile() +
      scale_fill_gradient2(low = "blue", mid = "white", high = "red", midpoint = 0) +
      theme_minimal() +
      theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
      labs(title = "Grafica A2: Mapa de correlación (num) - student_mat") +
      coord_fixed()
    print(p3)
  }
} else {
  cat("Archivo student-mat.csv no encontrado o vacío.\n")
}
```


Teniendo en cuenta aquellas que superan el parametro de correlaciones fuertes (|r|>=0.7) se tiene el siguiente listado:

```{r mat-strong}
# Correlaciones fuertes |r| >= 0.7 (numéricas)
if (nrow(df_mat) > 0) {
  nums <- df_mat %>% select(where(is.numeric))
  strong_mat <- tibble()
  if (ncol(nums) >= 2) {
    cor_mat <- cor(nums, use = "pairwise.complete.obs")
    cor_df <- as.data.frame(as.table(cor_mat))
    strong_mat <- cor_df %>%
      filter(Var1 != Var2) %>%
      mutate(abs_r = abs(Freq)) %>%
      filter(abs_r >= 0.7) %>%
      arrange(desc(abs_r)) %>%
      rename(variable1 = Var1, variable2 = Var2, r = Freq) %>%
      select(variable1, variable2, r)
  }

  if (nrow(strong_mat) > 0) {
    strong_mat %>% kable(digits = 3, caption = "Tabla A3: Correlaciones fuertes (|r|>=0.7) — student_mat") %>% kable_styling(full_width = FALSE)
  } else cat("No se detectaron correlaciones fuertes (|r|>=0.7) en variables numéricas.\n")
} else cat("Archivo student-mat.csv no encontrado o vacío.\n")
```

Para visualizar gráficamente las relaciones con mayor correlación (|r| notable), se muestran a continuación diagramas de dispersión entre G3 y cada variable relevante, junto con su línea de tendencia.

```{r mat-scatter}
if (nrow(df_mat)>0) {
  nums <- df_mat %>% select(where(is.numeric))
  if ("G3" %in% names(nums) && ncol(nums) >= 2) {
    cor_with_G3 <- cor(nums, use = "pairwise.complete.obs")[, "G3", drop = FALSE]
    cor_with_G3 <- tibble(variable = rownames(cor_with_G3), corr = cor_with_G3[,1]) %>%
      filter(variable != "G3") %>%
      arrange(desc(abs(corr)))
    top_vars <- head(cor_with_G3$variable, 6)
    if (length(top_vars) > 0) {
      scatter_df <- df_mat %>% select(all_of(c("G3", top_vars))) %>% pivot_longer(-G3, names_to = "variable", values_to = "value")
      p4 <- ggplot(scatter_df, aes(x = value, y = G3)) +
        geom_point(alpha = 0.6, size = 1.5, color = "#2b8cbe") +
        geom_smooth(method = "lm", se = FALSE, color = "red") +
        facet_wrap(~variable, scales = "free_x") +
        labs(title = "Grafico A6: G3 vs variables con mayor correlación (student_mat)") +
        theme_minimal()
      print(p4)
    }
  }
} else cat("Archivo student-mat.csv no encontrado o vacío.\n")
```

De los variables evaluadas, únicamente G1 y G2 alcanzan una correlación aceptable con la nota final (G3), por lo que se recomiendan como predictores prioritarios en la regresión lineal simple.


**Análisis Categorico**

Con el objetivo de analizar el comportamiento de las variables categóricas y detectar posibles valores atípicos, se presenta a continuación un gráfico que muestra la distribución de cada categoría.

```{r mat-cat-bars-improved, fig.width=12, fig.height=10, echo=FALSE}
library(ggplot2)
library(forcats)
library(scales)
library(dplyr)

cat_vars <- df_mat %>% select(where(~ is.character(.) || is.factor(.)))

if (nrow(df_mat) > 0 && ncol(cat_vars) > 0) {

  # Long format y conteo inicial
  long_cat <- cat_vars %>%
    mutate(across(everything(), ~ as.character(.))) %>%
    pivot_longer(everything(), names_to = "variable", values_to = "value") %>%
    filter(!is.na(value))

  counts <- long_cat %>%
    group_by(variable, value) %>%
    summarise(n = n(), .groups = "drop") %>%
    group_by(variable) %>%
    arrange(variable, desc(n)) %>%
    mutate(rank = row_number()) %>%
    ungroup()

  # Agrupar categorías raras por variable (top 10 -> mostrar; resto -> "Other")
  counts2 <- counts %>%
    mutate(value2 = if_else(rank <= 10, value, "Other")) %>%
    group_by(variable, value2) %>%
    summarise(n = sum(n), .groups = "drop") %>%
    group_by(variable) %>%
    mutate(pct = n / sum(n) * 100) %>%
    ungroup()

  # Preparar factor reordenado dentro de cada facet
  counts2 <- counts2 %>%
    group_by(variable) %>%
    mutate(value2 = fct_reorder2(value2, n, n)) %>%
    ungroup()

  # Plot: barras horizontales por variable (faceteado)
  p <- ggplot(counts2, aes(x = value2, y = n, fill = pct)) +
    geom_col(width = 0.7, show.legend = TRUE) +
    geom_text(aes(label = paste0(ifelse(pct < 1, "<1", round(pct,1)), "%")), 
              position = position_stack(vjust = 0.5), color = "white", size = 3) +
    facet_wrap(~ variable, scales = "free_y", ncol = 2) +
    coord_flip() +
    scale_fill_viridis_c(option = "plasma", name = "Pct (%)") +
    scale_y_continuous(expand = expansion(mult = c(0, 0.05))) +
    labs(title = "Grafico A7: Distribución de categorías — student_mat (top10 por variable; resto = Other)",
         x = NULL, y = "Conteo") +
    theme_minimal(base_size = 11) +
    theme(strip.text = element_text(face = "bold", size = 10),
          axis.text.y = element_text(size = 8),
          legend.position = "right")

  print(p)

  # Tabla de categorías de baja frecuencia (umbral: pct < 2% o n < 5)
  low_thresh_pct <- 2
  low_thresh_n <- 5
  low_counts <- counts2 %>%
    filter(pct < low_thresh_pct | n < low_thresh_n) %>%
    arrange(variable, pct)

  if (nrow(low_counts) > 0) {
    cat("\nCategorías de baja frecuencia (posibles atípicos):\n")
    low_counts %>%
      select(variable, value2, n, pct) %>%
      distinct() %>%
      knitr::kable(digits = 2, caption = "Categorías con baja frecuencia (student_mat)") %>%
      kableExtra::kable_styling(full_width = FALSE)
  } else {
    cat("\nNo se encontraron categorías de baja frecuencia según el umbral (pct < ", low_thresh_pct, "% o n < ", low_thresh_n, ").\n", sep = "")
  }
} else {
  cat("No hay variables categóricas en student_mat o el dataset está vacío.\n")
}
```

Gráfico de barras faceteado: distribución por categoría para cada variable categórica (se agrupan las categorías de baja frecuencia como "Other"). Útil para identificar valores atípicos y desbalances en las categorías.
De esta manera se puede visualizar que no existen variables atipicas en este conjunto de datos con respecto a las variables categoricas del dataset **student_mat**

## Resumen numérico: missing, Outlier and Correlation (student_por)

A continuació se genera un resumen numerico del dataset **student_por** reflejando estadisticamente valores que visualizan si es necesario imputar datos o limpiar registros en cuento a valores atipico o faltantes:

```{r por-numeric}
# Crear resumen numérico directamente a partir de student-por.csv
if (nrow(df_por) > 0) {
  num_sum_por <- df_por %>%
    select(where(is.numeric)) %>%
    summarise(across(everything(), list(
      mean = ~mean(.x, na.rm = TRUE),
      sd = ~sd(.x, na.rm = TRUE),
      median = ~median(.x, na.rm = TRUE),
      min = ~min(.x, na.rm = TRUE),
      max = ~max(.x, na.rm = TRUE),
      missing = ~sum(is.na(.x))
    ), .names = "{.col}_{.fn}"))

  # Convertir a formato largo para mostrar
  num_sum_por_long <- num_sum_por %>%
    pivot_longer(everything(), names_to = "metric", values_to = "value") %>%
    separate(metric, into = c("variable","stat"), sep = "_(?=[^_]+$)") %>%
    pivot_wider(names_from = stat, values_from = value) %>%
    arrange(variable)

  num_sum_por_long %>%
    kable(digits = 3, caption = "Tabla B5: Resumen numerico student_mat") %>%
    kable_styling(full_width = FALSE)
} else cat("Archivo student-mat.csv no encontrado o vacío.\n")
```

En el siguiente espacio se desea revisar toda la data **student_por** con el fin de determinar si existen valores faltantes y asi iniciar un procedimiento de imputación de datos:

```{r por-missing}
# Tabla de valores faltantes por variable (student_por) — mostrar solo variables con missing > 0
if (nrow(df_por) > 0) {
  missing_por <- df_por %>%
    summarise(across(everything(), ~sum(is.na(.)))) %>%
    pivot_longer(everything(), names_to = "variable", values_to = "missing") %>%
    arrange(desc(missing))

  missing_por_filtered <- missing_por %>% filter(missing > 0)

  if (nrow(missing_por_filtered) > 0) {
    missing_por_filtered %>%
      kable(digits = 0, caption = "Missing values — student_mat (solo variables con missing)") %>%
      kable_styling(full_width = FALSE)
  } else {
    cat("No se detectaron valores faltantes en student_mat.\n")
  }
} else cat("Archivo student-mat.csv no encontrado o vacío.\n")
```
Y como se puede visualizar el codigo arroja que la data no contiene valores faltantes, por lo que continuaremos con la sigueinte sesion.

### Boxplots y Correlación

A continuacion se grafican las variables numericas graficos **Boxplots** para visualizar las diferentes variables que presentan alguna posible variacion atipica en su conjunto de valores, como se pueden ver en las variables: Walc, traveltime, studytime, Medu, health, goout, G3, G2, G1, freetime, Fedu, famrel, failures, Dalc, age, y absences en la grafica B1:


```{r por_plots}
if (nrow(df_por)>0) {
  library(ggplot2)
  # Boxplots por variables numéricas
  nums <- df_por %>% select(where(is.numeric))
  if (ncol(nums) > 0) {
    nums_long <- nums %>% pivot_longer(everything(), names_to = "variable", values_to = "value")
    p2 <- ggplot(nums_long, aes(x = variable, y = value)) +
      geom_boxplot(outlier.size = 1, fill = "#74a9cf") +
      coord_flip() +
      labs(title = "Grafica B1: Boxplots variables numéricas (student_por)") +
      theme_minimal()
    print(p2)
  }
} else {
  cat("Archivo student-por.csv no encontrado o vacío.\n")
}
```

Aplicando la funcionalidad de detección de **Outliers** visualizamos en la sigueinte tabla (Tabla B4) la cantidad de valores que no se ajustan al rango o regla **IQR**.

```{r por-outliers}
# Detección de outliers por regla IQR para variables numéricas
if (nrow(df_por) > 0) {
  nums <- df_por %>% select(where(is.numeric))
  out_por <- map_dfr(names(nums), function(var) {
    x <- nums[[var]]
    if (all(is.na(x))) return(tibble(variable = var, outlier_count = 0))
    q1 <- quantile(x, 0.25, na.rm = TRUE)
    q3 <- quantile(x, 0.75, na.rm = TRUE)
    iqr <- q3 - q1
    lower <- q1 - 1.5 * iqr
    upper <- q3 + 1.5 * iqr
    tibble(variable = var, outlier_count = sum(x < lower | x > upper, na.rm = TRUE))
  })

  out_por %>% filter(outlier_count > 0) %>%
    kable(digits = 0, caption = "Tabla B4: Outliers detectados (IQR) — student_por") %>%
    kable_styling(full_width = FALSE)
} else cat("Archivo student-mat.csv no encontrado o vacío.\n")
```

En el siguiente grafico (Grafica B2) se realiza un grafico de correlación con las variables numericas con el fin de encontrar la posible relacion que puede existir en algunas variables tales como G1, G2, G3, Walc, Dalc, Fedu y Medu.

```{r por_correlacion}
if (nrow(df_por)>0) {
  library(ggplot2)
  # Mapa de correlación (numéricas)
  nums <- df_por %>% select(where(is.numeric))
  if (ncol(nums) >= 2) {
    cor_por <- cor(nums, use = "pairwise.complete.obs")
    cor_df <- as.data.frame(as.table(cor_por))
    p3 <- ggplot(cor_df, aes(Var1, Var2, fill = Freq)) +
      geom_tile() +
      scale_fill_gradient2(low = "blue", mid = "white", high = "red", midpoint = 0) +
      theme_minimal() +
      theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
      labs(title = "Grafica B2: Mapa de correlación (num) - student_por") +
      coord_fixed()
    print(p3)
  }
} else {
  cat("Archivo student-mat.csv no encontrado o vacío.\n")
}
```


Teniendo en cuenta aquellas que superan el parametro de correlaciones fuertes (|r|>=0.7) se tiene el siguiente listado:

```{r por-strong}
# Correlaciones fuertes |r| >= 0.7 (numéricas)
if (nrow(df_por) > 0) {
  nums <- df_por %>% select(where(is.numeric))
  strong_por <- tibble()
  if (ncol(nums) >= 2) {
    cor_por <- cor(nums, use = "pairwise.complete.obs")
    cor_df <- as.data.frame(as.table(cor_por))
    strong_por <- cor_df %>%
      filter(Var1 != Var2) %>%
      mutate(abs_r = abs(Freq)) %>%
      filter(abs_r >= 0.7) %>%
      arrange(desc(abs_r)) %>%
      rename(variable1 = Var1, variable2 = Var2, r = Freq) %>%
      select(variable1, variable2, r)
  }

  if (nrow(strong_por) > 0) {
    strong_por %>% kable(digits = 3, caption = "Tabla B3: Correlaciones fuertes (|r|>=0.7) — student_por") %>% kable_styling(full_width = FALSE)
  } else cat("No se detectaron correlaciones fuertes (|r|>=0.7) en variables numéricas.\n")
} else cat("Archivo student-mat.csv no encontrado o vacío.\n")
```

Para visualizar gráficamente las relaciones con mayor correlación (|r| notable), se muestran a continuación diagramas de dispersión entre G3 y cada variable relevante, junto con su línea de tendencia.

```{r por-scatter}
if (nrow(df_por)>0) {
  nums <- df_por %>% select(where(is.numeric))
  if ("G3" %in% names(nums) && ncol(nums) >= 2) {
    cor_with_G3 <- cor(nums, use = "pairwise.complete.obs")[, "G3", drop = FALSE]
    cor_with_G3 <- tibble(variable = rownames(cor_with_G3), corr = cor_with_G3[,1]) %>%
      filter(variable != "G3") %>%
      arrange(desc(abs(corr)))
    top_vars <- head(cor_with_G3$variable, 6)
    if (length(top_vars) > 0) {
      scatter_df <- df_mat %>% select(all_of(c("G3", top_vars))) %>% pivot_longer(-G3, names_to = "variable", values_to = "value")
      p4 <- ggplot(scatter_df, aes(x = value, y = G3)) +
        geom_point(alpha = 0.6, size = 1.5, color = "#2b8cbe") +
        geom_smooth(method = "lm", se = FALSE, color = "red") +
        facet_wrap(~variable, scales = "free_x") +
        labs(title = "Grafico B6: G3 vs variables con mayor correlación (student_por)") +
        theme_minimal()
      print(p4)
    }
  }
} else cat("Archivo student-por.csv no encontrado o vacío.\n")
```

De los variables evaluadas, únicamente G1 y G2 alcanzan una correlación aceptable con la nota final (G3), por lo que se recomiendan como predictores prioritarios en la regresión lineal simple.

**Análisis Categorico**

Con el objetivo de analizar el comportamiento de las variables categóricas y detectar posibles valores atípicos, se presenta a continuación un gráfico que muestra la distribución de cada categoría.

```{r por-cat-bars-improved, fig.width=12, fig.height=10, echo=FALSE}
library(ggplot2)
library(forcats)
library(scales)
library(dplyr)

cat_vars <- df_por %>% select(where(~ is.character(.) || is.factor(.)))

if (nrow(df_por) > 0 && ncol(cat_vars) > 0) {

  # Long format y conteo inicial
  long_cat <- cat_vars %>%
    mutate(across(everything(), ~ as.character(.))) %>%
    pivot_longer(everything(), names_to = "variable", values_to = "value") %>%
    filter(!is.na(value))

  counts <- long_cat %>%
    group_by(variable, value) %>%
    summarise(n = n(), .groups = "drop") %>%
    group_by(variable) %>%
    arrange(variable, desc(n)) %>%
    mutate(rank = row_number()) %>%
    ungroup()

  # Agrupar categorías raras por variable (top 10 -> mostrar; resto -> "Other")
  counts2 <- counts %>%
    mutate(value2 = if_else(rank <= 10, value, "Other")) %>%
    group_by(variable, value2) %>%
    summarise(n = sum(n), .groups = "drop") %>%
    group_by(variable) %>%
    mutate(pct = n / sum(n) * 100) %>%
    ungroup()

  # Preparar factor reordenado dentro de cada facet
  counts2 <- counts2 %>%
    group_by(variable) %>%
    mutate(value2 = fct_reorder2(value2, n, n)) %>%
    ungroup()

  # Plot: barras horizontales por variable (faceteado)
  p <- ggplot(counts2, aes(x = value2, y = n, fill = pct)) +
    geom_col(width = 0.7, show.legend = TRUE) +
    geom_text(aes(label = paste0(ifelse(pct < 1, "<1", round(pct,1)), "%")), 
              position = position_stack(vjust = 0.5), color = "white", size = 3) +
    facet_wrap(~ variable, scales = "free_y", ncol = 2) +
    coord_flip() +
    scale_fill_viridis_c(option = "plasma", name = "Pct (%)") +
    scale_y_continuous(expand = expansion(mult = c(0, 0.05))) +
    labs(title = "Grafico B7: Distribución de categorías — student_por (top10 por variable; resto = Other)",
         x = NULL, y = "Conteo") +
    theme_minimal(base_size = 11) +
    theme(strip.text = element_text(face = "bold", size = 10),
          axis.text.y = element_text(size = 8),
          legend.position = "right")

  print(p)

  # Tabla de categorías de baja frecuencia (umbral: pct < 2% o n < 5)
  low_thresh_pct <- 2
  low_thresh_n <- 5
  low_counts <- counts2 %>%
    filter(pct < low_thresh_pct | n < low_thresh_n) %>%
    arrange(variable, pct)

  if (nrow(low_counts) > 0) {
    cat("\nCategorías de baja frecuencia (posibles atípicos):\n")
    low_counts %>%
      select(variable, value2, n, pct) %>%
      distinct() %>%
      knitr::kable(digits = 2, caption = "Categorías con baja frecuencia (student_mat)") %>%
      kableExtra::kable_styling(full_width = FALSE)
  } else {
    cat("\nNo se encontraron categorías de baja frecuencia según el umbral (pct < ", low_thresh_pct, "% o n < ", low_thresh_n, ").\n", sep = "")
  }
} else {
  cat("No hay variables categóricas en student_por o el dataset está vacío.\n")
}
```

Gráfico de barras faceteado: distribución por categoría para cada variable categórica (se agrupan las categorías de baja frecuencia como "Other"). Útil para identificar valores atípicos y desbalances en las categorías.
De esta manera se puede visualizar que no existen variables atipicas en este conjunto de datos con respecto a las variables categoricas del dataset **student_por**

## Histograma de la variable objetivo G3 (student_mat)

A continuación se construye un histograma de la variable objetivo (G3) para examinar su distribución y características principales (asimetría, multimodalidad, concentración y posibles valores extremos), con el fin de extraer conclusiones sobre su comportamiento antes del modelado.


```{r Mat_Histograma_G3, fig.width=8, fig.height=4}
if (nrow(df_mat) > 0 && "G3" %in% names(df_mat)) {
  library(ggplot2)
  g3 <- df_mat$G3
  g3 <- g3[!is.na(g3)]
  if (length(g3) > 1 && sd(g3) > 0) {
    mu <- mean(g3)
    sigma <- sd(g3)
    p1 <- ggplot(df_mat, aes(x = G3)) +
      geom_histogram(aes(y = ..density..), binwidth = 1, fill = "#2c7fb8", color = "white") +
      stat_function(fun = dnorm, args = list(mean = mu, sd = sigma), color = "red", size = 1) +
      geom_density(alpha = 0.15, fill = "red", color = NA) +  # opcional: densidad kernel
      labs(title = "Grafica A8: Distribución de G3 (student_mat)",
           subtitle = paste0("Normal ajustada: μ=", round(mu,2), ", σ=", round(sigma,2)),
           x = "G3", y = "Densidad") +
      theme_minimal()
    print(p1)
  } else {
    cat("G3 no tiene suficientes observaciones válidas o sd = 0.\n")
  }
} else {
  cat("Archivo student-mat.csv no encontrado, vacío o columna G3 ausente.\n")
}
```

**Estadísticos mostrados:** 
media ≈ 10.4, desviación estándar ≈ 4.6.

**Forma general:** distribución aproximadamente unimodal con pico alrededor de calificaciones entre 9–11; la campana normal ajustada aproxima bien el centro pero no captura totalmente los extremos.

**Desviaciones respecto a la normal:** presencia de valores muy bajos (cúmulo cercano a 0) y una cola derecha moderada — ligera asimetría/colas más pesadas que la normal.

**Implicaciones para modelado:** la normalidad no es perfecta pero suficiente como punto de partida; se deben validar residuos tras ajustar el modelo.

**Recomendaciones preliminares:** proceder con regresión lineal simple usando G3, para ello se debe revisar influencias (outliers), heterocedasticidad.


## Histograma de la variable objetivo G3 (student_por)
A continuación se construye un histograma de la variable objetivo (G3) para examinar su distribución y características principales (asimetría, multimodalidad, concentración y posibles valores extremos), con el fin de extraer conclusiones sobre su comportamiento antes del modelado.


```{r Por_Histograma_G3, fig.width=8, fig.height=4}
if (nrow(df_por) > 0 && "G3" %in% names(df_por)) {
  library(ggplot2)
  g3 <- df_por$G3
  g3 <- g3[!is.na(g3)]
  if (length(g3) > 1 && sd(g3) > 0) {
    mu <- mean(g3)
    sigma <- sd(g3)
    p1 <- ggplot(df_por, aes(x = G3)) +
      geom_histogram(aes(y = ..density..), binwidth = 1, fill = "#2c7fb8", color = "white") +
      stat_function(fun = dnorm, args = list(mean = mu, sd = sigma), color = "red", size = 1) +
      geom_density(alpha = 0.15, fill = "red", color = NA) +  # opcional: densidad kernel
      labs(title = "Grafica B8: Distribución de G3 (student_por)",
           subtitle = paste0("Normal ajustada: μ=", round(mu,2), ", σ=", round(sigma,2)),
           x = "G3", y = "Densidad") +
      theme_minimal()
    print(p1)
  } else {
    cat("G3 no tiene suficientes observaciones válidas o sd = 0.\n")
  }
} else {
  cat("Archivo student-por.csv no encontrado, vacío o columna G3 ausente.\n")
}
```

**Estadísticos mostrados:** 
media ≈ 11.9, desviación estándar ≈ 3.2.

**Forma general:** distribución aproximadamente unimodal con pico alrededor de calificaciones entre 10–11; la campana normal ajustada aproxima bien el centro pero no captura totalmente los extremos.

**Desviaciones respecto a la normal:** presencia de valores muy bajos (cúmulo cercano a 0) y una cola derecha moderada — ligera asimetría/colas más pesadas que la normal.

**Implicaciones para modelado:** la normalidad no es perfecta pero suficiente como punto de partida; se deben validar residuos tras ajustar el modelo.

**Recomendaciones preliminares:** proceder con regresión lineal simple usando G3, para ello se debe revisar influencias (outliers), heterocedasticidad.

## Conclusiones EDA 

Actualmente en el proyecto los datos no muestran valores faltantes (por lo que en un caso hipotetico **median_imputed** y **mice_pooled** no aportarían cambios útiles). Existen outliers detectados por IQR y si se buscara es reducir su influencia en la regresión sin eliminar observaciones ni introducir demasiada suposición **Winsorizar** conservaría el tamaño de la muestra y reduciría el sesgo que los extremos causaría en estimadores basados en la media y en OLS (Ordinary Least Squares / Mínimos Cuadrados Ordinarios)

Ahora, para el caso que estamos estudiando de las calificaciones de los estudiantes y la prediccion de la variable de salida G3, ¿Es necesario imputar datos?, ¿Son realmente los valores atipicos valores regularmente no dados o imposibles de obtener en las calificaciones?

Segun el documento de investigacion https://repositorium.sdum.uminho.pt/bitstream/1822/8024/1/student.pdf la calificación posible de un alumno oscila desde 0 hasta 20, y basado en el análisis exploratorio realizado, se concluye que:

**Calidad de los datos:** Las base de datos `student_mat` y `student_por` se encuentran limpia, sin valores faltantes relevantes y los valores extremos detectados corresponden a calificaciones plausibles dentro del rango académico 0-20, por lo que no requieren imputación o eliminación.

**Variables objetivo y predictores:** La variable `G3` (nota final) en amabos datasets presentan una distribución aproximadamente unimodal con ligera asimetría, siendo adecuada para modelado con regresión lineal. Las variables `G1` y `G2` en ambos datasets igualmente mostraron correlaciones más altas con `G3`, identificándose como los predictores más prometedores.

**Preparación para modelado:** Los datos están listos para proceder con la aplicación de un modelo de regresión lineal simple, donde se evaluará la relación entre las notas previas y la calificación final.

### Comparación entre datasets

```{r compare-summary}
# dimensiones y conteos de missing
mat_missing_total <- if (nrow(df_mat) > 0) sum(is.na(df_mat)) else NA
por_missing_total <- if (nrow(df_por) > 0) sum(is.na(df_por)) else NA

mat_dims <- if (nrow(df_mat) > 0) dim(df_mat) else c(NA,NA)
por_dims <- if (nrow(df_por) > 0) dim(df_por) else c(NA,NA)

comp_tab <- tibble(
  dataset = c("student_mat","student_por"),
  rows = c(mat_dims[1], por_dims[1]),
  cols = c(mat_dims[2], por_dims[2]),
  total_missing = c(mat_missing_total, por_missing_total)
)

comp_tab %>% kable(caption = "Comparación resumida entre datasets") %>% kable_styling(full_width = FALSE)
```


# Definición: Modelo de Regresión Lienal Simple (SLMR)

La **regresión lineal simple** es una técnica estadística que modela la relación lineal entre dos variables cuantitativas: una variable independiente o predictora (X) y una variable dependiente o respuesta (Y). Su objetivo es encontrar la mejor línea recta que describa la relación entre estas variables y permita realizar predicciones.

## Modelo Matemático

El modelo de regresión lineal simple se expresa mediante la ecuación:

$$Y_i = \beta_0 + \beta_1 X_i + \varepsilon_i$$

Donde:
- $Y_i$ = variable dependiente (respuesta) para la observación i
- $X_i$ = variable independiente (predictora) para la observación i  
- $\beta_0$ = intercepto (ordenada al origen)
- $\beta_1$ = pendiente (coeficiente de regresión)
- $\varepsilon_i$ = término de error aleatorio

## Estimación por Mínimos Cuadrados Ordinarios (OLS)

Los parámetros $\beta_0$ y $\beta_1$ se estiman minimizando la suma de cuadrados de los residuos:

$$\min \sum_{i=1}^{n} (Y_i - \hat{Y_i})^2 = \min \sum_{i=1}^{n} (Y_i - \beta_0 - \beta_1 X_i)^2$$

Las fórmulas de estimación son:

$$\hat{\beta_1} = \frac{\sum_{i=1}^{n}(X_i - \bar{X})(Y_i - \bar{Y})}{\sum_{i=1}^{n}(X_i - \bar{X})^2}$$

$$\hat{\beta_0} = \bar{Y} - \hat{\beta_1}\bar{X}$$

## Supuestos del Modelo

Para que la regresión lineal simple sea válida, deben cumplirse los siguientes supuestos:

1. **Linealidad**: La relación entre X e Y es lineal
2. **Independencia**: Las observaciones son independientes
3. **Homocedasticidad**: La varianza de los errores es constante
4. **Normalidad**: Los errores siguen una distribución normal
5. **No multicolinealidad**: (No aplica en regresión simple)

## Métricas de Evaluación

- **Coeficiente de Determinación (R²)**: Proporción de variabilidad de Y explicada por X
  $$R^2 = \frac{\text{Variabilidad Explicada}}{\text{Variabilidad Total}} = \frac{SSR}{SST}$$

- **Error Estándar Residual**: Medida de dispersión de los residuos
  $$s = \sqrt{\frac{\sum_{i=1}^{n}(Y_i - \hat{Y_i})^2}{n-2}}$$

## Interpretación de Coeficientes

- **$\hat{\beta_0}$**: Valor esperado de Y cuando X = 0
- **$\hat{\beta_1}$**: Cambio promedio en Y por cada unidad de incremento en X


# Aplicación: Regresión Lineal Simple (student_mat)

En nuestro análisis del dataset `student_mat`, aplicamos regresión lineal simple para modelar la relación entre las calificaciones previas (G1 o G2) y la nota final (G3), permitiendo predecir el rendimiento académico final basado en el desempeño previo del estudiante.


## Selección de Variables Predictoras

Se identifican y seleccionan las variables con mayor poder predictivo basándose en las correlaciones calculadas en el EDA. Este paso es fundamental para construir un modelo moderado y efectivo.

```{r slr-variable-selection, results='asis'}
# Selección de variables predictoras basada en correlación con G3
if (nrow(df_mat) > 0) {
  library(dplyr)
  library(knitr)
  
  # Calcular correlaciones con G3 para todas las variables numéricas
  nums <- df_mat %>% select(where(is.numeric))
  
  if ("G3" %in% names(nums)) {
    cor_with_g3 <- cor(nums, use = "pairwise.complete.obs")[, "G3", drop = FALSE]
    
    # Crear tabla ordenada de correlaciones
    cor_table <- tibble(
      variable = rownames(cor_with_g3),
      correlacion = as.numeric(cor_with_g3[,1])
    ) %>%
      filter(variable != "G3") %>%
      arrange(desc(abs(correlacion))) %>%
      mutate(
        correlacion = round(correlacion, 4),
        abs_correlacion = round(abs(correlacion), 4)
      )
    
    # Mostrar tabla de correlaciones
    cor_table %>%
      head(10) %>%
      kable(caption = "Tabla 7.1: Variables numéricas ordenadas por correlación con G3", 
            format = "html") %>%
      kable_styling(full_width = FALSE, 
                    bootstrap_options = c("striped", "hover", "condensed")) %>%
      cat()
    
    # Identificar el mejor predictor
    best_predictor <- cor_table$variable[1]
    best_correlation <- cor_table$correlacion[1]
    
    cat("\n Por lo tanto, la variable seleccionada para la regresión es:", best_predictor, 
        "\n con una correlación de:", round(best_correlation, 4), "\n con respecto a G3")
  }
} else {
  cat("Dataset student_mat no disponible para análisis.")
}
```

## Visualización de la Relación Lineal

Antes del ajuste formal, se explora visualmente la relación entre el predictor seleccionado y la variable objetivo para confirmar la adequacidad de un modelo lineal y identificar posibles patrones o valores influyentes.

```{r slr-scatter-plot, fig.width=8, fig.height=6, results='asis'}
# Gráfico de dispersión con línea de tendencia
if (nrow(df_mat) > 0 && exists("best_predictor")) {
  library(ggplot2)
  
  # Crear el gráfico de dispersión
  p_scatter <- ggplot(df_mat, aes_string(x = best_predictor, y = "G3")) +
    geom_point(alpha = 0.6, size = 2, color = "#2b8cbe") +
    geom_smooth(method = "lm", se = TRUE, color = "red", fill = "pink", alpha = 0.3) +
    labs(
      title = paste("Gráfico 7.1: Relación entre", best_predictor, "y G3"),
      subtitle = paste("Correlación r =", round(best_correlation, 4)),
      x = paste(best_predictor, "(Variable Predictora)"),
      y = "G3 (Nota Final)"
    ) +
    theme_minimal() +
    theme(
      plot.title = element_text(size = 14, face = "bold"),
      plot.subtitle = element_text(size = 12),
      axis.title = element_text(size = 11)
    )
  
  print(p_scatter)
  
  # Estadísticas descriptivas de ambas variables
  stats_table <- df_mat %>%
    select(all_of(c(best_predictor, "G3"))) %>%
    summarise(
      across(everything(), list(
        n = ~sum(!is.na(.)),
        media = ~round(mean(., na.rm = TRUE), 2),
        sd = ~round(sd(., na.rm = TRUE), 2),
        min = ~min(., na.rm = TRUE),
        max = ~max(., na.rm = TRUE)
      ), .names = "{.col}_{.fn}")
    ) %>%
    pivot_longer(everything(), names_to = "stat", values_to = "value") %>%
    separate(stat, into = c("variable", "estadistico"), sep = "_(?=[^_]+$)") %>%
    pivot_wider(names_from = estadistico, values_from = value)
  
  stats_table %>%
    kable(caption = "Tabla 7.2: Estadísticas descriptivas de las variables del modelo", 
          format = "html") %>%
    kable_styling(full_width = FALSE, 
                  bootstrap_options = c("striped", "hover", "condensed")) %>%
    cat()
  
} else {
  cat("No se puede generar el gráfico: datos o predictor no disponibles.")
}
```

## Ajuste del Modelo de Regresión Lineal Simple

Se ajusta el modelo de regresión lineal simple utilizando mínimos cuadrados ordinarios (OLS) y se extraen los coeficientes principales junto con sus medidas de significancia estadística.

```{r slr-model-fit, results='asis'}
# Ajuste del modelo de regresión lineal simple
if (nrow(df_mat) > 0 && exists("best_predictor")) {
  library(broom)
  
  # Crear fórmula del modelo
  formula_str <- paste("G3 ~", best_predictor)
  model_formula <- as.formula(formula_str)
  
  # Ajustar el modelo
  slr_model <- lm(model_formula, data = df_mat)
  
  # Resumen del modelo
  model_summary <- summary(slr_model)
  
  # Extraer coeficientes usando broom para formato tidy
  coefficients_table <- tidy(slr_model) %>%
    mutate(
      estimate = round(estimate, 4),
      std.error = round(std.error, 4),
      statistic = round(statistic, 3),
      p.value = ifelse(p.value < 0.001, "< 0.001", round(p.value, 4))
    ) %>%
    rename(
      Término = term,
      Coeficiente = estimate,
      `Error Estándar` = std.error,
      `Estadístico t` = statistic,
      `Valor p` = p.value
    )
  
  # Mostrar tabla de coeficientes
  coefficients_table %>%
    kable(caption = "Tabla 7.3: Coeficientes del modelo de regresión lineal simple", 
          format = "html") %>%
    kable_styling(full_width = FALSE, 
                  bootstrap_options = c("striped", "hover", "condensed")) %>%
    cat()
  
  # Métricas de bondad de ajuste
  model_metrics <- tibble(
    Métrica = c("R-cuadrado", "R-cuadrado ajustado", "Error estándar residual", "Estadístico F", "Valor p del modelo"),
    Valor = c(
      round(model_summary$r.squared, 4),
      round(model_summary$adj.r.squared, 4),
      round(model_summary$sigma, 4),
      round(model_summary$fstatistic[1], 3),
      ifelse(pf(model_summary$fstatistic[1], model_summary$fstatistic[2], model_summary$fstatistic[3], lower.tail = FALSE) < 0.001, 
             "< 0.001", 
             round(pf(model_summary$fstatistic[1], model_summary$fstatistic[2], model_summary$fstatistic[3], lower.tail = FALSE), 4))
    )
  )
  
  model_metrics %>%
    kable(caption = "Tabla 7.4: Métricas de bondad de ajuste del modelo", 
          format = "html") %>%
    kable_styling(full_width = FALSE, 
                  bootstrap_options = c("striped", "hover", "condensed")) %>%
    cat()
  
  # Ecuación del modelo
  intercept <- round(coefficients(slr_model)[1], 4)
  slope <- round(coefficients(slr_model)[2], 4)
  
  cat("\n**Ecuación del modelo ajustado:**")
  cat("\nG3 =", intercept, "+", slope, "×", best_predictor)
  cat("\n\n**Interpretación:**")
  cat("\n- Por cada unidad adicional en", best_predictor, ", G3 aumenta en promedio", slope, "puntos")
  cat("\n- El modelo explica", round(model_summary$r.squared * 100, 2), "% de la variabilidad en G3")
  
} else {
  cat("No se puede ajustar el modelo: datos o predictor no disponibles.")
}
```

## Validación de Supuestos del Modelo

Se verifican los supuestos fundamentales de la regresión lineal: linealidad, homocedasticidad, normalidad de residuos e independencia. Esta validación es crucial para confirmar la validez de las inferencias estadísticas.

```{r slr-assumptions, fig.width=12, fig.height=8}
# Validación de supuestos del modelo
if (exists("slr_model")) {
  library(ggplot2)
  library(gridExtra)
  
  # Calcular residuos y valores ajustados
  model_data <- augment(slr_model)
  
  # 1. Gráfico de residuos vs valores ajustados (homocedasticidad y linealidad)
  p1 <- ggplot(model_data, aes(x = .fitted, y = .resid)) +
    geom_point(alpha = 0.6, color = "#2b8cbe") +
    geom_hline(yintercept = 0, color = "red", linetype = "dashed") +
    geom_smooth(method = "loess", se = FALSE, color = "orange") +
    labs(
      title = "Residuos vs Valores Ajustados",
      subtitle = "Evaluación de linealidad y homocedasticidad",
      x = "Valores Ajustados",
      y = "Residuos"
    ) +
    theme_minimal()
  
  # 2. Q-Q plot para normalidad de residuos
  p2 <- ggplot(model_data, aes(sample = .resid)) +
    stat_qq(alpha = 0.6, color = "#2b8cbe") +
    stat_qq_line(color = "red") +
    labs(
      title = "Q-Q Plot de Residuos",
      subtitle = "Evaluación de normalidad",
      x = "Cuantiles Teóricos",
      y = "Cuantiles de Residuos"
    ) +
    theme_minimal()
  
  # 3. Histograma de residuos
  p3 <- ggplot(model_data, aes(x = .resid)) +
    geom_histogram(aes(y = ..density..), bins = 20, fill = "#2b8cbe", alpha = 0.7, color = "white") +
    geom_density(color = "red", size = 1) +
    stat_function(fun = dnorm, args = list(mean = mean(model_data$.resid), sd = sd(model_data$.resid)), 
                  color = "orange", linetype = "dashed", size = 1) +
    labs(
      title = "Distribución de Residuos",
      subtitle = "Comparación con distribución normal",
      x = "Residuos",
      y = "Densidad"
    ) +
    theme_minimal()
  
  # 4. Gráfico de distancia de Cook
  p4 <- ggplot(model_data, aes(x = seq_along(.cooksd), y = .cooksd)) +
    geom_point(alpha = 0.6, color = "#2b8cbe") +
    geom_hline(yintercept = 4/nrow(model_data), color = "red", linetype = "dashed") +
    labs(
      title = "Distancia de Cook",
      subtitle = "Identificación de observaciones influyentes",
      x = "Índice de Observación",
      y = "Distancia de Cook"
    ) +
    theme_minimal()
  
  # Combinar gráficos
  grid.arrange(p1, p2, p3, p4, ncol = 2, nrow = 2,
               top = "Gráfico 7.2: Diagnósticos del modelo de regresión lineal simple")
  
  # Pruebas formales de supuestos
  cat("\n**Pruebas estadísticas de supuestos:**\n")
  
  # Test de Shapiro-Wilk para normalidad (si n <= 5000)
  if (length(residuals(slr_model)) <= 5000) {
    shapiro_test <- shapiro.test(residuals(slr_model))
    cat("Normalidad de residuos (Shapiro-Wilk):")
    cat("\n  W =", round(shapiro_test$statistic, 4))
    cat("\n  p-valor =", ifelse(shapiro_test$p.value < 0.001, "< 0.001", round(shapiro_test$p.value, 4)))
    cat("\n  Interpretación:", ifelse(shapiro_test$p.value > 0.05, "No rechazar normalidad", "Rechazar normalidad"))
  }
  
  # Test de Breusch-Pagan para homocedasticidad (requiere lmtest)
  if (requireNamespace("lmtest", quietly = TRUE)) {
    library(lmtest)
    bp_test <- bptest(slr_model)
    cat("\n\nHomocedasticidad (Breusch-Pagan):")
    cat("\n  BP =", round(bp_test$statistic, 4))
    cat("\n  p-valor =", ifelse(bp_test$p.value < 0.001, "< 0.001", round(bp_test$p.value, 4)))
    cat("\n  Interpretación:", ifelse(bp_test$p.value > 0.05, "No rechazar homocedasticidad", "Rechazar homocedasticidad"))
  }
  
  # Identificar observaciones influyentes
  influential_obs <- which(model_data$.cooksd > 4/nrow(model_data))
  
  if (length(influential_obs) > 0) {
    cat("\n\nObservaciones influyentes (Distancia de Cook > 4/n):")
    cat("\n  Observaciones:", paste(influential_obs, collapse = ", "))
    cat("\n  Total:", length(influential_obs), "de", nrow(model_data), "observaciones")
  } else {
    cat("\n\nNo se detectaron observaciones influyentes significativas.")
  }
  
} else {
  cat("Modelo no disponible para validación de supuestos.")
}
```

## Análisis de Residuos y Predicciones

Se realiza un análisis detallado de los residuos para evaluar la calidad del ajuste y se generan predicciones con sus respectivos intervalos de confianza.

```{r slr-predictions, results='asis'}
# Análisis de residuos y predicciones
if (exists("slr_model")) {
  
  # Estadísticas de residuos
  residuos <- residuals(slr_model)
  residuos_stats <- tibble(
    Estadística = c("Media", "Desviación Estándar", "Mínimo", "Q1", "Mediana", "Q3", "Máximo"),
    Valor = c(
      round(mean(residuos), 4),
      round(sd(residuos), 4),
      round(min(residuos), 4),
      round(quantile(residuos, 0.25), 4),
      round(median(residuos), 4),
      round(quantile(residuos, 0.75), 4),
      round(max(residuos), 4)
    )
  )
  
  residuos_stats %>%
    kable(caption = "Tabla 7.5: Estadísticas descriptivas de los residuos", 
          format = "html") %>%
    kable_styling(full_width = FALSE, 
                  bootstrap_options = c("striped", "hover", "condensed")) %>%
    cat()
  
  # Generar predicciones con intervalos de confianza
  pred_data <- tibble(!!sym(best_predictor) := seq(min(df_mat[[best_predictor]], na.rm = TRUE),
                                                    max(df_mat[[best_predictor]], na.rm = TRUE),
                                                    length.out = 50))
  
  predictions <- predict(slr_model, newdata = pred_data, interval = "confidence", level = 0.95)
  pred_results <- bind_cols(pred_data, as_tibble(predictions))
  
  # Gráfico de predicciones con intervalos de confianza
  p_pred <- ggplot() +
    # Datos originales
    geom_point(data = df_mat, aes_string(x = best_predictor, y = "G3"), 
               alpha = 0.6, size = 2, color = "#2b8cbe") +
    # Línea de regresión
    geom_line(data = pred_results, aes_string(x = best_predictor, y = "fit"), 
              color = "red", size = 1) +
    # Intervalos de confianza
    geom_ribbon(data = pred_results, aes_string(x = best_predictor, ymin = "lwr", ymax = "upr"), 
                alpha = 0.2, fill = "red") +
    labs(
      title = "Gráfico 7.3: Modelo ajustado con intervalos de confianza",
      subtitle = paste("IC del 95% para la media de G3 dado", best_predictor),
      x = paste(best_predictor, "(Variable Predictora)"),
      y = "G3 (Nota Final)"
    ) +
    theme_minimal() +
    theme(
      plot.title = element_text(size = 14, face = "bold"),
      plot.subtitle = element_text(size = 12)
    )
  
  print(p_pred)
  
  # Tabla de predicciones ejemplo
  ejemplo_valores <- c(
    round(quantile(df_mat[[best_predictor]], c(0.1, 0.25, 0.5, 0.75, 0.9), na.rm = TRUE))
  )
  
  pred_ejemplo <- predict(slr_model, 
                          newdata = tibble(!!sym(best_predictor) := ejemplo_valores), 
                          interval = "prediction", level = 0.95)
  
  ejemplo_table <- tibble(
    !!sym(paste(best_predictor, "(Valor)")) := ejemplo_valores,
    `G3 Predicho` = round(pred_ejemplo[,"fit"], 2),
    `Límite Inferior (95%)` = round(pred_ejemplo[,"lwr"], 2),
    `Límite Superior (95%)` = round(pred_ejemplo[,"upr"], 2)
  )
  
  ejemplo_table %>%
    kable(caption = paste("Tabla 7.6: Ejemplos de predicción con intervalos del 95%"), 
          format = "html") %>%
    kable_styling(full_width = FALSE, 
                  bootstrap_options = c("striped", "hover", "condensed")) %>%
    cat()
  
} else {
  cat("Modelo no disponible para generar predicciones.")
}
```

## Interpretación Final y Conclusiones del Modelo

Se presenta una síntesis completa de los resultados obtenidos, incluyendo la interpretación práctica de los coeficientes, la evaluación de la calidad del modelo y las recomendaciones para su uso.

```{r slr-conclusions}
# Interpretación final y conclusiones
if (exists("slr_model")) {
  
  cat("**CONCLUSIONES DEL MODELO DE REGRESIÓN LINEAL SIMPLE**\n")
  cat(paste(rep("=", 60), collapse = ""), "\n\n")
  
  # Información del modelo
  model_summary <- summary(slr_model)
  intercept <- round(coefficients(slr_model)[1], 4)
  slope <- round(coefficients(slr_model)[2], 4)
  r_squared <- round(model_summary$r.squared, 4)
  adj_r_squared <- round(model_summary$adj.r.squared, 4)
  
  cat("**1. MODELO AJUSTADO:**\n")
  cat("   Ecuación: G3 =", intercept, "+", slope, "×", best_predictor, "\n")
  cat("   Variable predictora:", best_predictor, "\n")
  cat("   Variable respuesta: G3 (Nota Final)\n\n")
  
  cat("**2. CALIDAD DEL AJUSTE:**\n")
  cat("   R² =", r_squared, "(", round(r_squared * 100, 2), "% de variabilidad explicada)\n")
  cat("   R² ajustado =", adj_r_squared, "\n")
  cat("   Error estándar residual =", round(model_summary$sigma, 4), "\n\n")
  
  cat("**3. SIGNIFICANCIA ESTADÍSTICA:**\n")
  coef_pvalue <- summary(slr_model)$coefficients[2, 4]
  cat("   Coeficiente de", best_predictor, ":", 
      ifelse(coef_pvalue < 0.001, "altamente significativo (p < 0.001)", 
             paste("significativo (p =", round(coef_pvalue, 4), ")")), "\n")
  
  f_pvalue <- pf(model_summary$fstatistic[1], model_summary$fstatistic[2], model_summary$fstatistic[3], lower.tail = FALSE)
  cat("   Modelo global:", 
      ifelse(f_pvalue < 0.001, "altamente significativo (p < 0.001)", 
             paste("significativo (p =", round(f_pvalue, 4), ")")), "\n\n")
  
  cat("**4. INTERPRETACIÓN PRÁCTICA:**\n")
  cat("   - Por cada punto adicional en", best_predictor, ", la nota final (G3)")
  cat(ifelse(slope > 0, " aumenta ", " disminuye "))
  cat("en promedio", abs(slope), "puntos\n")
  
  cat("   - El modelo predice que un estudiante con", best_predictor, "= 0 tendría")
  cat(" una nota final de", intercept, "puntos (intercepción)\n")
  
  cat("   - La correlación observada (r =", round(sqrt(r_squared), 4), ") indica una relación")
  if (sqrt(r_squared) >= 0.7) {
    cat(" fuerte")
  } else if (sqrt(r_squared) >= 0.5) {
    cat(" moderada")
  } else {
    cat(" débil a moderada")
  }
  cat(" entre las variables\n\n")
  
  cat("**5. VALIDACIÓN DE SUPUESTOS:**\n")
  
  # Verificar supuestos
  supuestos_ok <- TRUE
  
  # Shapiro-Wilk si aplica
  if (length(residuals(slr_model)) <= 5000) {
    shapiro_p <- shapiro.test(residuals(slr_model))$p.value
    cat("   - Normalidad de residuos:", 
        ifelse(shapiro_p > 0.05, "CUMPLE", "NO CUMPLE"), 
        "(Shapiro-Wilk p =", round(shapiro_p, 4), ")\n")
    if (shapiro_p <= 0.05) supuestos_ok <- FALSE
  }
  
  # Breusch-Pagan si está disponible
  if (requireNamespace("lmtest", quietly = TRUE)) {
    bp_p <- lmtest::bptest(slr_model)$p.value
    cat("   - Homocedasticidad:", 
        ifelse(bp_p > 0.05, "CUMPLE", "NO CUMPLE"), 
        "(Breusch-Pagan p =", round(bp_p, 4), ")\n")
    if (bp_p <= 0.05) supuestos_ok <- FALSE
  }
  
  # Observaciones influyentes
  cooksd <- cooks.distance(slr_model)
  influential_count <- sum(cooksd > 4/length(cooksd))
  cat("   - Observaciones influyentes:", influential_count, "de", length(cooksd), 
      ifelse(influential_count <= 0.05 * length(cooksd), "(ACEPTABLE)", "(REVISAR)"), "\n\n")
  
  cat("**6. RECOMENDACIONES:**\n")
  
  if (r_squared >= 0.5 && supuestos_ok) {
    cat("   ✓ El modelo es APROPIADO para predicción con las siguientes características:\n")
    cat("     - Poder predictivo", ifelse(r_squared >= 0.7, "alto", "moderado"), "\n")
    cat("     - Cumple supuestos estadísticos\n")
    cat("     - Relación significativa entre variables\n")
  } else if (r_squared >= 0.3) {
    cat("   ⚠ El modelo es ÚTIL pero con limitaciones:\n")
    if (r_squared < 0.5) cat("     - Poder predictivo limitado (R² < 0.5)\n")
    if (!supuestos_ok) cat("     - Algunos supuestos no se cumplen completamente\n")
    cat("     - Considerar variables adicionales o transformaciones\n")
  } else {
    cat("   ✗ El modelo tiene LIMITACIONES importantes:\n")
    cat("     - Bajo poder predictivo (R² < 0.3)\n")
    cat("     - Buscar variables predictoras más relevantes\n")
    cat("     - Considerar modelos más complejos\n")
  }
  
  cat("\n**7. USO PRÁCTICO:**\n")
  cat("   Para predecir G3 de un nuevo estudiante, use la ecuación:\n")
  cat("   G3_predicho =", intercept, "+", slope, "× valor_de_", best_predictor, "\n")
  cat("   (Considere los intervalos de predicción para incertidumbre)\n")
  
} else {
  cat("Modelo no disponible para generar conclusiones.")
}
```

---

```r
rmarkdown::render("StudyCase_EDA_Report.Rmd")
```



